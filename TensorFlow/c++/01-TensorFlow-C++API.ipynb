{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow C++\n",
    "\n",
    "### 1. 自定义操作\n",
    "\n",
    "在 TF 的官方文档中，定义一个操作，需要我们调用 `REGSITER_OP` 宏来注册。\n",
    "\n",
    "```c++\n",
    "REGISTER_OP(\"ZeroOut\")\n",
    "    .Input(\"to_zero: int32\")\n",
    "    .Output(\"zeroed: int32\")\n",
    "    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\n",
    "      c->set_output(0, c->input(0));\n",
    "      return Status::OK();\n",
    "    });\n",
    "```\n",
    "\n",
    "那么这个宏到底是什么那？下面就根据源文件进行下 Crash.\n",
    "\n",
    "`/tensorflow/core/framework/op.h`.\n",
    "\n",
    "```c++\n",
    "#define REGISTER_OP(name) REGISTER_OP_UNIQ_HELPER(__COUNTER__, name)\n",
    "#define REGISTER_OP_UNIQ_HELPER(ctr, name) REGISTER_OP_UNIQ(ctr, name)\n",
    "#define REGISTER_OP_UNIQ(ctr, name)                                          \\\n",
    "  static ::tensorflow::register_op::OpDefBuilderReceiver register_op##ctr    \\\n",
    "      TF_ATTRIBUTE_UNUSED =                                                  \\\n",
    "          ::tensorflow::register_op::OpDefBuilderWrapper<SHOULD_REGISTER_OP( \\\n",
    "              name)>(name)\n",
    "```\n",
    "\n",
    "要理解上面的宏，需要的知识点：\n",
    "\n",
    "- `\\` 代码换行\n",
    "- `##` 字符连接\n",
    "- `TF_ATTRIBUTE_UNUSED` 其是 `#define TF_ATTRIBUTE_UNUSED __attribute__((unused))` 的宏定义。\n",
    "- `__COUNTER__` 预处理器定义的自增量，遇到就会加一。\n",
    "\n",
    "那么 `REGISTER_OP(\"ZeroOut\")` 就会被预处理为：\n",
    "\n",
    "```c++\n",
    "static ::tensorflow::register_op::OpDefBuilderReceiver register_op1 __attribute__((unused)) = ::tensorflow::register_op::OpDefBuilderWrapper<true>(\"ZeroOut\");\n",
    "```\n",
    "\n",
    "让我们再简化上面的声明语句:\n",
    "\n",
    "```c++\n",
    "static OpDefBuilderReceiver register_op1 = OpDefBuilderWrapper<true>(\"ZeroOut\");\n",
    "```\n",
    "\n",
    "现在出现了 `OpDefBuilderReceiver` 和 `OpDefBuilderWrapper` 两个类型。那让我们从 `OpDefBuilderWrapper` 开始 crash.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 `OpDefBuilderWrapper`\n",
    "\n",
    "从 `Wrapper` 这个后缀可以看出其是一包裹类 `/tensorflow/core/framework/op.h` 。\n",
    "\n",
    "```c++\n",
    "// OpDefBuilderWrapper is a templated class that is used in the REGISTER_OP\n",
    "// calls. This allows the result of REGISTER_OP to be used in chaining, as in\n",
    "// REGISTER_OP(a).Attr(\"...\").Input(\"...\");, while still allowing selective\n",
    "// registration to turn the entire call-chain into a no-op.\n",
    "template <bool should_register>\n",
    "class OpDefBuilderWrapper;\n",
    "\n",
    "// Template specialization that forwards all calls to the contained builder.\n",
    "template <>\n",
    "class OpDefBuilderWrapper<true> {\n",
    "   public:\n",
    "    explicit OpDefBuilderWrapper(const char name[]) : builder_(name) {}\n",
    "    OpDefBuilderWrapper<true>& Attr(string spec) {\n",
    "      builder_.Attr(std::move(spec));\n",
    "      return *this;\n",
    "    }\n",
    "    OpDefBuilderWrapper<true>& Input(string spec) {\n",
    "      builder_.Input(std::move(spec));\n",
    "      return *this;\n",
    "    }\n",
    "    OpDefBuilderWrapper<true>& Output(string spec) {\n",
    "      builder_.Output(std::move(spec));\n",
    "      return *this;\n",
    "    }\n",
    "    OpDefBuilderWrapper<true>& SetIsCommutative() {\n",
    "      builder_.SetIsCommutative();\n",
    "      return *this;\n",
    "    }\n",
    "    OpDefBuilderWrapper<true>& SetIsAggregate() {\n",
    "      builder_.SetIsAggregate();\n",
    "      return *this;\n",
    "    }\n",
    "    OpDefBuilderWrapper<true>& SetIsStateful() {\n",
    "      builder_.SetIsStateful();\n",
    "      return *this;\n",
    "    }\n",
    "    OpDefBuilderWrapper<true>& SetAllowsUninitializedInput() {\n",
    "      builder_.SetAllowsUninitializedInput();\n",
    "      return *this;\n",
    "    }\n",
    "    OpDefBuilderWrapper<true>& Deprecated(int version, string explanation) {\n",
    "      builder_.Deprecated(version, std::move(explanation));\n",
    "      return *this;\n",
    "    }\n",
    "    OpDefBuilderWrapper<true>& Doc(string text) {\n",
    "      builder_.Doc(std::move(text));\n",
    "      return *this;\n",
    "    }\n",
    "    OpDefBuilderWrapper<true>& SetShapeFn(\n",
    "        Status (*fn)(shape_inference::InferenceContext*)) {\n",
    "      builder_.SetShapeFn(fn);\n",
    "      return *this;\n",
    "    }\n",
    "    const ::tensorflow::OpDefBuilder& builder() const { return builder_; }\n",
    "\n",
    "   private:\n",
    "    mutable ::tensorflow::OpDefBuilder builder_;\n",
    "}\n",
    "```\n",
    "\n",
    "从文件的注释中我们也看到了，该包裹类的上的就是了让其包裹的 `OpDefBuilder builder_` 通过以链式的写法调用。实现也很方便就是将所有调用传递给 builder_ 调用，然后返回 `*this` 就行了。\n",
    "\n",
    "`class OpDefBuilderWrapper<true>` 对应的还有一个 `class OpDefBuilderWrapper<false>` 两者的区别就是会不会去完成注册。\n",
    "\n",
    "那目前为止，我们包裹的 `OpDefBuidler` 类是做什么的那？该类定义在 `tensorflow/core/framework/op_def_builder.h`。\n",
    "\n",
    "```c++\n",
    "// Builder class passed to the REGISTER_OP() macro.\n",
    "class OpDefBuilder {\n",
    " public:\n",
    "  // Constructs an OpDef with just the name field set.\n",
    "  explicit OpDefBuilder(string op_name);\n",
    "\n",
    "  // Adds an attr to this OpDefBuilder (and returns *this). The spec has\n",
    "  // format \"<name>:<type>\" or \"<name>:<type>=<default>\"\n",
    "  // where <name> matches regexp [a-zA-Z][a-zA-Z0-9_]*\n",
    "  // (by convention only using capital letters for attrs that can be inferred)\n",
    "  // <type> can be:\n",
    "  //   \"string\", \"int\", \"float\", \"bool\", \"type\", \"shape\", or \"tensor\"\n",
    "  //   \"numbertype\", \"realnumbertype\", \"quantizedtype\"\n",
    "  //       (meaning \"type\" with a restriction on valid values)\n",
    "  //   \"{int32,int64}\" or {realnumbertype,quantizedtype,string}\"\n",
    "  //       (meaning \"type\" with a restriction containing unions of value types)\n",
    "  //   \"{\\\"foo\\\", \\\"bar\\n baz\\\"}\", or \"{'foo', 'bar\\n baz'}\"\n",
    "  //       (meaning \"string\" with a restriction on valid values)\n",
    "  //   \"list(string)\", ..., \"list(tensor)\", \"list(numbertype)\", ...\n",
    "  //       (meaning lists of the above types)\n",
    "  //   \"int >= 2\" (meaning \"int\" with a restriction on valid values)\n",
    "  //   \"list(string) >= 2\", \"list(int) >= 2\"\n",
    "  //       (meaning \"list(string)\" / \"list(int)\" with length at least 2)\n",
    "  // <default>, if included, should use the Proto text format\n",
    "  // of <type>.  For lists use [a, b, c] format.\n",
    "  //\n",
    "  // Note that any attr specifying the length of an input or output will\n",
    "  // get a default minimum of 1 unless the >= # syntax is used.\n",
    "  //\n",
    "  // TODO(josh11b): Perhaps support restrictions and defaults as optional\n",
    "  // extra arguments to Attr() instead of encoding them in the spec string.\n",
    "  // TODO(josh11b): Would like to have better dtype handling for tensor attrs:\n",
    "  // * Ability to say the type of an input/output matches the type of\n",
    "  //   the tensor.\n",
    "  // * Ability to restrict the type of the tensor like the existing\n",
    "  //   restrictions for type attrs.\n",
    "  // Perhaps by linking the type of the tensor to a type attr?\n",
    "  OpDefBuilder& Attr(string spec);\n",
    "\n",
    "  // Adds an input or output to this OpDefBuilder (and returns *this).\n",
    "  // The spec has form \"<name>:<type-expr>\" or \"<name>:Ref(<type-expr>)\"\n",
    "  // where <name> matches regexp [a-z][a-z0-9_]* and <type-expr> can be:\n",
    "  // * For a single tensor: <type>\n",
    "  // * For a sequence of tensors with the same type: <number>*<type>\n",
    "  // * For a sequence of tensors with different types: <type-list>\n",
    "  // Where:\n",
    "  //   <type> is either one of \"float\", \"int32\", \"string\", ...\n",
    "  //                 or the name of an attr (see above) with type \"type\".\n",
    "  //   <number> is the name of an attr with type \"int\".\n",
    "  //   <type-list> is the name of an attr with type \"list(type)\".\n",
    "  // TODO(josh11b): Indicate Ref() via an optional argument instead of\n",
    "  // in the spec?\n",
    "  // TODO(josh11b): SparseInput() and SparseOutput() matching the Python\n",
    "  // handling?\n",
    "  OpDefBuilder& Input(string spec);\n",
    "  OpDefBuilder& Output(string spec);\n",
    "\n",
    "  // Turns on the indicated boolean flag in this OpDefBuilder (and\n",
    "  // returns *this).\n",
    "  OpDefBuilder& SetIsCommutative();\n",
    "  OpDefBuilder& SetIsAggregate();\n",
    "  OpDefBuilder& SetIsStateful();\n",
    "  OpDefBuilder& SetAllowsUninitializedInput();\n",
    "\n",
    "  // Deprecate the op at a certain GraphDef version.\n",
    "  OpDefBuilder& Deprecated(int version, string explanation);\n",
    "\n",
    "  // Adds docs to this OpDefBuilder (and returns *this).\n",
    "  // Docs have the format:\n",
    "  //   <1-line summary>\n",
    "  //   <rest of the description>\n",
    "  //   <name>: <description of name>\n",
    "  //   <name>: <description of name>\n",
    "  //     <if long, indent the description on subsequent lines>\n",
    "  // Where <name> is the name of an attr, input, or output.  Please\n",
    "  // wrap docs at 72 columns so that it may be indented in the\n",
    "  // generated output.  For tensor inputs or outputs (not attrs), you\n",
    "  // may start the description with an \"=\" (like name:= <description>)\n",
    "  // to suppress the automatically-generated type documentation in\n",
    "  // generated output.\n",
    "#ifndef TF_LEAN_BINARY\n",
    "  OpDefBuilder& Doc(string text);\n",
    "#else\n",
    "  OpDefBuilder& Doc(string text) { return *this; }\n",
    "#endif\n",
    "\n",
    "  // Sets the shape function to be used for shape inference.\n",
    "  //\n",
    "  // Note that currently (October 2016), python code still requires a\n",
    "  // RegisterShape call to invoke this; see call_cpp_shape_fn in\n",
    "  // python/framework/common_shapes.py\n",
    "  OpDefBuilder& SetShapeFn(OpShapeInferenceFn fn);\n",
    "\n",
    "  // Sets op_reg_data->op_def to the requested OpDef and\n",
    "  // op_reg_data->shape_inference_fn to the requested shape inference function,\n",
    "  // or returns an error.\n",
    "  // Must be called after all of the above methods.\n",
    "  //\n",
    "  // Note that OpDefBuilder only reports parsing errors.  You should also\n",
    "  // call ValidateOpDef() to detect other problems.\n",
    "  Status Finalize(OpRegistrationData* op_reg_data) const;\n",
    "\n",
    " private:\n",
    "  friend class FunctionDefHelper;\n",
    "\n",
    "  // Adds control output to this OpDefBuilder (and returns *this).\n",
    "  // The <name> must be a valid node name (matches regexp\n",
    "  // [a-zA-Z][a-zA-Z0-9_]*). Named control output can only exist for functions.\n",
    "  OpDefBuilder& ControlOutput(string name);\n",
    "\n",
    "  OpDef* op_def() { return &op_reg_data_.op_def; }\n",
    "\n",
    "  OpRegistrationData op_reg_data_;\n",
    "  std::vector<string> attrs_;\n",
    "  std::vector<string> inputs_;\n",
    "  std::vector<string> outputs_;\n",
    "  std::vector<string> control_outputs_;\n",
    "  string doc_;\n",
    "  std::vector<string> errors_;\n",
    "};\n",
    "\n",
    "```\n",
    "\n",
    "对类的定义进行下简化：\n",
    "\n",
    "```c++\n",
    "// Builder class passed to the REGISTER_OP() macro.\n",
    "class OpDefBuilder {\n",
    " public:\n",
    "  // Constructs an OpDef with just the name field set.\n",
    "  explicit OpDefBuilder(string op_name);\n",
    "  OpDefBuilder& Attr(string spec);\n",
    "  OpDefBuilder& Input(string spec);\n",
    "  OpDefBuilder& Output(string spec);\n",
    "  OpDefBuilder& SetIsCommutative();\n",
    "  OpDefBuilder& SetIsAggregate();\n",
    "  OpDefBuilder& SetIsStateful();\n",
    "  OpDefBuilder& SetAllowsUninitializedInput();\n",
    "  OpDefBuilder& Deprecated(int version, string explanation);\n",
    "  OpDefBuilder& Doc(string text);\n",
    "  OpDefBuilder& SetShapeFn(OpShapeInferenceFn fn);\n",
    "  Status Finalize(OpRegistrationData* op_reg_data) const;\n",
    "\n",
    " private:\n",
    "  friend class FunctionDefHelper;\n",
    "  OpDefBuilder& ControlOutput(string name);\n",
    "  OpDef* op_def() { return &op_reg_data_.op_def; }\n",
    "  OpRegistrationData op_reg_data_;\n",
    "  std::vector<string> attrs_;\n",
    "  std::vector<string> inputs_;\n",
    "  std::vector<string> outputs_;\n",
    "  std::vector<string> control_outputs_;\n",
    "  string doc_;\n",
    "  std::vector<string> errors_;\n",
    "};\n",
    "```\n",
    "\n",
    "上面除了构造函数需要传入 `op_name` 外，只有 `Input, Output, Attr, SetShapeFn, Doc, Deprecated` 需要我们传入参数。Doc 的功能顾名思义，Inpu, Output, Attr 需要我们按 `spec` 规则来传入符合规范的字符串，而 `SetShapeFn` 需要我们传入一个回调函数。\n",
    "\n",
    "- `Attr(string spec);` 为 `OpDefBuilder` [添加属性](https://www.tensorflow.org/guide/extend/op#op_registration)。\n",
    "\n",
    "  spec 的格式为：\"<name>:<type>\" 或 \"<name>:<type>=<default>\"\n",
    "\n",
    "  - <name>： 满足 `[a-zA-Z][a-zA-Z0-9_]*` 正则\n",
    "  - <type>：可以是一个简单的基础类型，也可以是复合类型：\n",
    "    - 基础类型：`string, int, float, bool, type, shape 或 tensor`等。\n",
    "    - 复合类型：`{int32,int64}, numbertype, realnumbertype ` 等。\n",
    "\n",
    "  - <default>： 为该属性添加默认值。\n",
    "\n",
    "- `Input(string spec)` \n",
    "\n",
    "- `Output(string sepc)`\n",
    "\n",
    "  `Input, Output` 定义的 spec 规范是一样的。\n",
    "\n",
    "  spec 的格式为：\"<name>:<type-expr>\" 或 \"<name>:Ref(<type-expr>)\"\n",
    "\n",
    "  - <name> :  满足 `[a-zA-Z][a-zA-Z0-9_]*` 正则\n",
    "\n",
    "  - <type-expr>: 可以是：\n",
    "\n",
    "    - 一个 tensor 的 type: `<type>`。即我们在操作张量时的 dtype.\n",
    "\n",
    "      ```python\n",
    "      In [106]: x = tf.matmul([[1]], [[2, 3]])\n",
    "      \n",
    "      In [107]: print(x)\n",
    "      tf.Tensor([[2 3]], shape=(1, 2), dtype=int32)\n",
    "      \n",
    "      In [100]: x = tf.sin(1.0)\n",
    "      \n",
    "      In [101]: print(x)\n",
    "      tf.Tensor(0.84147096, shape=(), dtype=float32)\n",
    "      \n",
    "      In [98]: type(x)\n",
    "      Out[98]: tensorflow.python.framework.ops.EagerTensor\n",
    "      \n",
    "      In [99]: print(x)\n",
    "      tf.Tensor(\n",
    "      [[0.35174477 0.88608444 0.72226477]\n",
    "       [0.21097851 0.12061656 0.81054926]\n",
    "       [0.7454673  0.06144464 0.46765244]], shape=(3, 3), dtype=float32)\n",
    "      ```\n",
    "\n",
    "      我们只需要定义，Tensor 的 `dtype` 就可以了，不要关心什么 `shape`. \n",
    "\n",
    "    - 同一类型的 tensor: `<number> * <type>`\n",
    "\n",
    "    - 不同类型的 tensor list: `[type-list]`\n",
    "\n",
    "  其中：`<type>, <number>, [type-list]` 的定义如下：\n",
    "\n",
    "  - <type> 可以是 `float, int32` 基础类型，也是复合类型。和 attr 中的 type 一样。\n",
    "  - <number> 是定义为 `int` 属性的属性名。\n",
    "  - <type-list> 是定义为 `list(type)` 属性的属性名。\n",
    "\n",
    "  ```c++\n",
    "    // Adds an input or output to this OpDefBuilder (and returns *this).\n",
    "    // The spec has form \"<name>:<type-expr>\" or \"<name>:Ref(<type-expr>)\"\n",
    "    // where <name> matches regexp [a-z][a-z0-9_]* and <type-expr> can be:\n",
    "    // * For a single tensor: <type>\n",
    "    // * For a sequence of tensors with the same type: <number>*<type>\n",
    "    // * For a sequence of tensors with different types: <type-list>\n",
    "    // Where:\n",
    "    //   <type> is either one of \"float\", \"int32\", \"string\", ...\n",
    "    //                 or the name of an attr (see above) with type \"type\".\n",
    "    //   <number> is the name of an attr with type \"int\".\n",
    "    //   <type-list> is the name of an attr with type \"list(type)\".\n",
    "  ```\n",
    "\n",
    "  当然 ，当我们需要添加的操作即需要支持 int 又要支持 float 怎么办那？我们当然也可以使用泛型来编程了，即, [多态类型](https://www.tensorflow.org/guide/extend/op#type_polymorphism)：\n",
    "\n",
    "  ```c++\n",
    "  REGISTER_OP(\"ZeroOut\")\n",
    "    .Attr(\"T: {float, int32} = DT_INT32\")\n",
    "    .Input(\"to_zero: T\")\n",
    "    .Output(\"zeroed: T\")\n",
    "  ```\n",
    "\n",
    "我们需要为每一种类型注册一个 `OpKernel`. 上面的操作注册说明输入类型必须是 `float` 和 `int32` 的，并且输出也是同一个类型，因为它们都具有 `T` 类型。\n",
    "\n",
    "那么我们可能需要写义两个 `Opkernel` ， 当然用泛型可以不用定义两个，但注册时还是需要的。即如下：\n",
    "\n",
    "```c++\n",
    "// Note that TypeConstraint<int32>(\"T\") means that attr \"T\" (defined\n",
    "// in the op registration above) must be \"int32\" to use this template\n",
    "// instantiation.\n",
    "REGISTER_KERNEL_BUILDER(\n",
    "    Name(\"ZeroOut\")\n",
    "    .Device(DEVICE_CPU)\n",
    "    .TypeConstraint<int32>(\"T\"),\n",
    "    ZeroOutOpInt32);\n",
    "REGISTER_KERNEL_BUILDER(\n",
    "    Name(\"ZeroOut\")\n",
    "    .Device(DEVICE_CPU)\n",
    "    .TypeConstraint<float>(\"T\"),\n",
    "    ZeroOutFloatOp);\n",
    "```\n",
    "\n",
    "在 `Input, Output` 中我们只定义了张量的类型，但是并没定义张量的形状，如果要定义张量的形状该怎么办那？要对张量的形状做验证和定义那就需要用到 InferenceContext 了。我们在例子中已经看到了 `SetShapeFn` 的用法。即：\n",
    "\n",
    "```c++\n",
    "REGISTER_OP(\"ZeroOut\")\n",
    "    .Input(\"to_zero: int32\")\n",
    "    .Output(\"zeroed: int32\")\n",
    "    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\n",
    "      c->set_output(0, c->input(0));\n",
    "      return Status::OK();\n",
    "    });\n",
    "```\n",
    "\n",
    "基中 c 是 InferenceContext 对象。InferenceContext 定义了些常用的方法，如：\n",
    "\n",
    "- `ShapeHandle input(int64 idx)` ：根据下标访问 Input 的值。其源代码如下：\n",
    "\n",
    "  ```c++\n",
    "  ShapeHandle input(int64 idx) const { return inputs_[idx]; }\n",
    "  ```\n",
    "\n",
    "  那么我们不禁要着呢 `inputs_` 是那里定义的，在那里赋值的？\n",
    "\n",
    "  这时的 `inputs_` 其实是基于我们的在定义操作时生成的，在注册时调用 `.Input(\"zeroed: int32\")` 方法时，其源码是这样的：\n",
    "\n",
    "  ```c++\n",
    "  OpDefBuilder& OpDefBuilder::Input(string spec) {\n",
    "    inputs_.push_back(std::move(spec));\n",
    "    return *this;\n",
    "  }\n",
    "  ```\n",
    "\n",
    "  所在 `SetShapeFn` 中 c-input(0) 获取第一个 (下标为 0 ) 的输入 `ShapeHandle` 就是我定义时调用的第一个 Input. 可见 Input, Output 我们可以定义多个，在验证时根据下标来验证，设置输出也根据下标输出。\n",
    "\n",
    "- set_output(index, shape)`： 根据下标设置 Out 的值。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### InferenceContext \n",
    "\n",
    "```c++\n",
    "// Shape inference functions registered on ops in REGISTER_OP implement\n",
    "// their shape functions in terms of this InferenceContext.  An InferenceContext\n",
    "// is created by the framework and passed to a shape inference function.  The\n",
    "// shape inference function calls functions on the context, and should call\n",
    "// set_output() to set the shape on all outputs.\n",
    "//\n",
    "// To infer shapes for user-defined functions see ShapeRefiner.\n",
    "//\n",
    "// All Shape* and Dimension* returned by functions of InferenceContext are owned\n",
    "// by the InferenceContext.\n",
    "class InferenceContext {\n",
    " public:\n",
    "  static constexpr int64 kUnknownDim = -1;\n",
    "  static constexpr int32 kUnknownRank = -1;\n",
    "\n",
    "  // <input_tensors> is NULL-padded to be the same size as <input_shapes>.\n",
    "  //\n",
    "  // Elements of <input_tensors_as_shapes> are used for when a shape function\n",
    "  // makes a call to MakeShapeFromShapeTensor; in particular, when the\n",
    "  // input_tensors[i] is nullptr but the shape represented by it is partially\n",
    "  // known from analysis of the graph.\n",
    "  // <input_tensors_as_shapes> can have fewer elements than <input_shapes>.\n",
    "  // Values of <input_tensors_as_shapes> do not need to outlive the context.\n",
    "  //\n",
    "  // REQUIRES: <node_def> is not NULL, and must outlive the InferenceContext.\n",
    "  InferenceContext(int graph_def_version, const NodeDef* node_def,\n",
    "                   const OpDef& op_def,\n",
    "                   const std::vector<ShapeHandle>& input_shapes,\n",
    "                   const std::vector<const Tensor*>& input_tensors,\n",
    "                   const std::vector<ShapeHandle>& input_tensors_as_shapes,\n",
    "                   std::vector<std::unique_ptr<std::vector<ShapeAndType>>>\n",
    "                       input_handle_shapes_and_types);\n",
    "\n",
    "  // <input_tensors> is NULL-padded to be the same size as <input_shapes>.\n",
    "  //\n",
    "  // Elements of <input_tensors_as_shapes> are used for when a shape\n",
    "  // function makes a call to MakeShapeFromShapeTensor; in particular, when\n",
    "  // the input_tensors[i] is nullptr but the shape represented by it is\n",
    "  // partially known from analysis of the graph. <input_tensors_as_shapes>\n",
    "  // can have fewer elements than <input_shapes>. Values of\n",
    "  // <input_tensors_as_shapes> do not need to outlive the context.\n",
    "  //\n",
    "  // REQUIRES: <node_def> is not NULL, and must outlive the\n",
    "  // InferenceContext.\n",
    "  InferenceContext(\n",
    "      int graph_def_version, const NodeDef* node_def, const OpDef& op_def,\n",
    "      const std::vector<TensorShapeProto>& input_shapes,\n",
    "      const std::vector<const Tensor*>& input_tensors,\n",
    "      const std::vector<TensorShapeProto>& input_tensors_as_shapes,\n",
    "      const std::vector<\n",
    "          std::unique_ptr<std::vector<std::pair<TensorShapeProto, DataType>>>>&\n",
    "          input_handle_shapes_and_types);\n",
    "\n",
    "  InferenceContext(\n",
    "      int graph_def_version, const NodeDef* node_def, const OpDef& op_def,\n",
    "      const std::vector<PartialTensorShape>& input_shapes,\n",
    "      const std::vector<const Tensor*>& input_tensors,\n",
    "      const std::vector<PartialTensorShape>& input_tensors_as_shapes,\n",
    "      const std::vector<std::unique_ptr<\n",
    "          std::vector<std::pair<PartialTensorShape, DataType>>>>&\n",
    "          input_handle_shapes_and_types);\n",
    "\n",
    "  ~InferenceContext();\n",
    "\n",
    "  Status Run(\n",
    "      const std::function<Status(shape_inference::InferenceContext* c)>& fn);\n",
    "\n",
    "  bool MergeInput(int idx, ShapeHandle shape);\n",
    "\n",
    "  bool RelaxInput(int idx, ShapeHandle shape);\n",
    "\n",
    "  void SetInput(int idx, ShapeHandle shape) { inputs_[idx] = shape; }\n",
    "\n",
    "  ShapeHandle input(int64 idx) const { return inputs_[idx]; }\n",
    "  Status input(StringPiece input_name, std::vector<ShapeHandle>* output) const;\n",
    "  int num_inputs() const { return inputs_.size(); }\n",
    "  const Tensor* input_tensor(int idx);\n",
    "  bool requested_input_tensor(int idx) const;\n",
    "  bool requested_input_tensor_as_partial_shape(int idx) const;\n",
    "\n",
    "  void set_input_tensors(const std::vector<const Tensor*>& input_tensors);\n",
    "\n",
    "  void set_input_tensors_as_shapes(\n",
    "      const std::vector<ShapeHandle>& input_tensors_as_shapes);\n",
    "\n",
    "  const std::vector<ShapeHandle>& input_tensors_as_shapes() const;\n",
    "\n",
    "  ShapeHandle output(int64 idx) const { return outputs_.at(idx); }\n",
    "  void set_output(int idx, ShapeHandle shape) { outputs_.at(idx) = shape; }\n",
    "  Status set_output(StringPiece output_name,\n",
    "                    const std::vector<ShapeHandle>& shapes);\n",
    "\n",
    "  int num_outputs() const { return outputs_.size(); }\n",
    "  ShapeHandle output(int idx) const { return outputs_.at(idx); }\n",
    "  Status output(StringPiece output_name,\n",
    "                std::vector<ShapeHandle>* output) const;\n",
    "\n",
    "  AttrSlice attrs() const { return AttrSlice(*node_def_); }\n",
    "\n",
    "  string op() const;\n",
    "\n",
    "  // idx can be negative for an offset from end of dimensions.\n",
    "  // idx must be in the range [-1 * s.rank, s.rank).\n",
    "  DimensionHandle Dim(ShapeHandle s, int64 idx);\n",
    "  // As above, but asserts that the rank of the shape is known.\n",
    "  static DimensionHandle DimKnownRank(ShapeHandle s, int64 idx);\n",
    "\n",
    "  static int32 Rank(ShapeHandle s) {\n",
    "    DCHECK(s.IsSet());\n",
    "    return s.IsSet() ? s->rank_ : kUnknownRank;\n",
    "  }\n",
    "  static bool RankKnown(ShapeHandle s) {\n",
    "    return (s.IsSet() && (Rank(s) != kUnknownRank));\n",
    "  }\n",
    "  static inline int64 Value(DimensionOrConstant d) {\n",
    "    return d.dim.IsSet() ? d.dim->value_ : d.val;\n",
    "  }\n",
    "  static inline bool ValueKnown(DimensionOrConstant d) {\n",
    "    return Value(d) != kUnknownDim;\n",
    "  }\n",
    "\n",
    "  // Fills the output proto with the shape defined by the handle.\n",
    "  // \"proto\" is expected to be empty prior to the call.\n",
    "  void ShapeHandleToProto(ShapeHandle handle, TensorShapeProto* proto);\n",
    "\n",
    "  // Returns true if the rank and all dimensions of the Shape are known.\n",
    "  bool FullyDefined(ShapeHandle s);\n",
    "\n",
    "  // Returns the total number of elements, or an unknown dimension for an\n",
    "  // incomplete shape.\n",
    "  DimensionHandle NumElements(ShapeHandle s);\n",
    "\n",
    "  // If <shape> has rank <rank>, or its rank is unknown, return OK and return\n",
    "  // the shape with asserted rank in <*out>. Otherwise return an error.\n",
    "  //\n",
    "  // Note that <*out> may be set to <shape>.\n",
    "  Status WithRank(ShapeHandle shape, int64 rank,\n",
    "                  ShapeHandle* out) TF_MUST_USE_RESULT;\n",
    "  Status WithRankAtLeast(ShapeHandle shape, int64 rank,\n",
    "                         ShapeHandle* out) TF_MUST_USE_RESULT;\n",
    "  Status WithRankAtMost(ShapeHandle shape, int64 rank,\n",
    "                        ShapeHandle* out) TF_MUST_USE_RESULT;\n",
    "\n",
    "  // If <dim> has value <value>, or its value is unknown, returns OK and returns\n",
    "  // the dimension with asserted value in <*out>. Otherwise returns an error.\n",
    "  //\n",
    "  // Note that <*out> may be set to <dim>.\n",
    "  Status WithValue(DimensionHandle dim, int64 value,\n",
    "                   DimensionHandle* out) TF_MUST_USE_RESULT;\n",
    "\n",
    "  // Merges <s0> and <s1> and returns the merged shape in <*out>. See\n",
    "  // 'MergeInput' function for full details and examples.\n",
    "  Status Merge(ShapeHandle s0, ShapeHandle s1,\n",
    "               ShapeHandle* out) TF_MUST_USE_RESULT;\n",
    "\n",
    "  // Asserts that <s>'s rank >= <prefix>'s rank, and the first\n",
    "  // <prefix.rank> dimensions of <s> are compatible with the dimensions of\n",
    "  // <prefix>.\n",
    "  // Returns the merged results in <*s_out> and <*prefix_out>.\n",
    "  Status MergePrefix(ShapeHandle s, ShapeHandle prefix, ShapeHandle* s_out,\n",
    "                     ShapeHandle* prefix_out) TF_MUST_USE_RESULT;\n",
    "\n",
    "  // Merges <d0> and <d1> and returns the merged dimension in <*out>. If <d0>\n",
    "  // and <d1> have incompatible values, returns an error.\n",
    "  //\n",
    "  // Note that <*out> may be set to <d0> or <d1>.\n",
    "  Status Merge(DimensionHandle d0, DimensionHandle d1,\n",
    "               DimensionHandle* out) TF_MUST_USE_RESULT;\n",
    "\n",
    "  // Returns in <*out> a sub-shape of <s> with dimensions [start:].\n",
    "  // <start> can be negative to index from the end of the shape. If <start> >\n",
    "  // rank of <s>, then an empty subshape is returned.\n",
    "  Status Subshape(ShapeHandle s, int64 start,\n",
    "                  ShapeHandle* out) TF_MUST_USE_RESULT;\n",
    "\n",
    "  // Returns in <*out> a sub-shape of <s>, with dimensions [start:end].\n",
    "  // <start> and <end> can be negative, to index from the end of the shape.\n",
    "  // <start> and <end> are set to the rank of <s> if > rank of <s>.\n",
    "  Status Subshape(ShapeHandle s, int64 start, int64 end,\n",
    "                  ShapeHandle* out) TF_MUST_USE_RESULT;\n",
    "\n",
    "  // Returns in <*out> a sub-shape of <s>, with dimensions [start:end:stride].\n",
    "  // <start> and <end> can be negative, to index from the end of the shape.\n",
    "  // <start> and <end> are set to the rank of <s> if > rank of <s>.\n",
    "  // <stride> can be negative, to reverse the <s>.\n",
    "  Status Subshape(ShapeHandle s, int64 start, int64 end, int64 stride,\n",
    "                  ShapeHandle* out) TF_MUST_USE_RESULT;\n",
    "\n",
    "  // Returns in <*out> the result of appending the dimensions of <s2> to those\n",
    "  // of <s1>.\n",
    "  Status Concatenate(ShapeHandle s1, ShapeHandle s2,\n",
    "                     ShapeHandle* out) TF_MUST_USE_RESULT;\n",
    "\n",
    "  // Returns in <out> the shape from replacing <s.dim[dim_index]> with\n",
    "  // <new_dim>.\n",
    "  Status ReplaceDim(ShapeHandle s, int64 dim_index, DimensionHandle new_dim,\n",
    "                    ShapeHandle* out) TF_MUST_USE_RESULT;\n",
    "\n",
    "  // Returns a new shape with the given dims. The returned value is owned by\n",
    "  // this context.\n",
    "  ShapeHandle MakeShape(const std::vector<DimensionHandle>& dims);\n",
    "  ShapeHandle MakeShape(std::initializer_list<DimensionOrConstant> dims);\n",
    "\n",
    "  // Returns a new unknown shape.\n",
    "  ShapeHandle UnknownShape();\n",
    "\n",
    "  // Returns a shape with specified rank but unknown dims.\n",
    "  ShapeHandle UnknownShapeOfRank(int64 rank);\n",
    "\n",
    "  // Returns a new shape of zero dimensions.\n",
    "  ShapeHandle Scalar();\n",
    "\n",
    "  // Returns a new shape of one dimension.\n",
    "  ShapeHandle Vector(DimensionOrConstant dim);\n",
    "\n",
    "  // Returns a new shape of two dimensions.\n",
    "  ShapeHandle Matrix(DimensionOrConstant dim1, DimensionOrConstant dim2);\n",
    "\n",
    "  // Returns in <out> a new shape whose dimension sizes come from input tensor\n",
    "  // <input_idx>. The tensor must be a 1-dimensional int32 or int64 tensor.  If\n",
    "  // the input tensor is NULL, then an unknown shape is returned.\n",
    "  Status MakeShapeFromShapeTensor(int input_idx, ShapeHandle* out);\n",
    "\n",
    "  // Like the function above, but treats scalar values as unknown\n",
    "  // shapes.  **NOTE** If the scalar is statically known, its value\n",
    "  // must be -1 or an error is returned.\n",
    "  Status MakeShapeFromShapeTensorTreatScalarAsUnknownShape(int input_idx,\n",
    "                                                           ShapeHandle* out);\n",
    "\n",
    "  // Returns in <out> a new shape corresponding to <proto>.\n",
    "  Status MakeShapeFromShapeProto(const TensorShapeProto& proto,\n",
    "                                 ShapeHandle* out);\n",
    "\n",
    "  // Returns in <out> a new shape corresponding to <partial_shape>.\n",
    "  Status MakeShapeFromPartialTensorShape(\n",
    "      const PartialTensorShape& partial_shape, ShapeHandle* out);\n",
    "\n",
    "  // Returns in <out> a new shape corresponding to <shape>.\n",
    "  Status MakeShapeFromTensorShape(const TensorShape& shape, ShapeHandle* out);\n",
    "\n",
    "  // Returns a new dimension of the given size.  The returned value is owned by\n",
    "  // this context.\n",
    "  inline DimensionHandle MakeDim(DimensionOrConstant d) {\n",
    "    return shape_manager_.MakeDim(d);\n",
    "  }\n",
    "\n",
    "  inline DimensionHandle UnknownDim() { return MakeDim(kUnknownDim); }\n",
    "\n",
    "  // Returns in <val> a scalar value from an input tensor <t>.  The input tensor\n",
    "  // must be a 1-dimensional int32 or int64 tensor.  Caller must ensure that the\n",
    "  // input tensor is not NULL.\n",
    "  Status GetScalarFromTensor(const Tensor* t, int64* val);\n",
    "\n",
    "  // Returns a new dimension whose value is given by a scalar input tensor.\n",
    "  // The input tensor must be in host memory, since it is dereferenced to get\n",
    "  // the value.\n",
    "  Status MakeDimForScalarInput(int idx, DimensionHandle* out);\n",
    "\n",
    "  // Returns a new dimension whose value is given by a scalar input tensor.\n",
    "  // This allows for a negative input dimension given the rank of a separate\n",
    "  // tensor.  This rank can be negative if unknown.\n",
    "  // The input tensor must be in host memory, since it is dereferenced to get\n",
    "  // the value.\n",
    "  Status MakeDimForScalarInputWithNegativeIndexing(int idx, int input_rank,\n",
    "                                                   DimensionHandle* out);\n",
    "\n",
    "  // Look up the attr for the NodeDef being evaluated with name attr_name and\n",
    "  // set *value to its value.  If no attr with attr_name is found in def(), or\n",
    "  // the attr does not have a matching type, a non-ok status will be returned.\n",
    "  template <class T>\n",
    "  Status GetAttr(StringPiece attr_name, T* value) const;\n",
    "\n",
    "  // Returns in <out> the result of dividing <dividend> by <divisor>.\n",
    "  // Returns an error if <divisor>  is not positive or if <evenly_divisible>\n",
    "  // and <divisor> does not evenly divide <dividend>.\n",
    "  Status Divide(DimensionHandle dividend, DimensionOrConstant divisor,\n",
    "                bool evenly_divisible, DimensionHandle* out);\n",
    "\n",
    "  // Returns in <out> the sum of <first> and <second>.\n",
    "  Status Add(DimensionHandle first, DimensionOrConstant second,\n",
    "             DimensionHandle* out);\n",
    "\n",
    "  // Returns in <out> the dimension that is <first> minus <second>.\n",
    "  Status Subtract(DimensionHandle first, DimensionOrConstant second,\n",
    "                  DimensionHandle* out);\n",
    "\n",
    "  // Returns in <out> the product of <first> and <second>.\n",
    "  Status Multiply(DimensionHandle first, DimensionOrConstant second,\n",
    "                  DimensionHandle* out);\n",
    "\n",
    "  // Returns in <out> the minimum of <first> and <second>. If either <first> or\n",
    "  // <second> is zero the results is zero. Otherwise, if either <first> or\n",
    "  // <second> is unknown the results is unknown.\n",
    "  Status Min(DimensionHandle first, DimensionOrConstant second,\n",
    "             DimensionHandle* out);\n",
    "\n",
    "  // Returns in <out> the maximum of <first> and <second>. If either <first> or\n",
    "  // <second> is unknown the results is unknown.\n",
    "  Status Max(DimensionHandle first, DimensionOrConstant second,\n",
    "             DimensionHandle* out);\n",
    "\n",
    "  Status construction_status() const { return construction_status_; }\n",
    "\n",
    "  bool MergeInputHandleShapesAndTypes(\n",
    "      int idx,\n",
    "      const std::vector<ShapeAndType>& shapes_and_types) TF_MUST_USE_RESULT;\n",
    "\n",
    "  // As MergeInputHandleShapesAndTypes, but for an output.\n",
    "  bool MergeOutputHandleShapesAndTypes(\n",
    "      int idx,\n",
    "      const std::vector<ShapeAndType>& shapes_and_types) TF_MUST_USE_RESULT;\n",
    "\n",
    "  bool RelaxInputHandleShapesAndMergeTypes(\n",
    "      int idx,\n",
    "      const std::vector<ShapeAndType>& shapes_and_types) TF_MUST_USE_RESULT;\n",
    "\n",
    "  // As RelaxInputHandleShapesAndTypes, but for an output.\n",
    "  bool RelaxOutputHandleShapesAndMergeTypes(\n",
    "      int idx,\n",
    "      const std::vector<ShapeAndType>& shapes_and_types) TF_MUST_USE_RESULT;\n",
    "\n",
    "  void set_input_handle_shapes_and_types(\n",
    "      int idx, const std::vector<ShapeAndType>& shapes_and_types) {\n",
    "    input_handle_shapes_and_types_[idx].reset(\n",
    "        new std::vector<ShapeAndType>(shapes_and_types));\n",
    "  }\n",
    "\n",
    "  // Returns the output handle shapes and types, for the resource tensor output\n",
    "  // at index <idx>. Returns NULL if the shape and types were never set.\n",
    "  const std::vector<ShapeAndType>* output_handle_shapes_and_types(int idx) {\n",
    "    return output_handle_shapes_and_types_[idx].get();\n",
    "  }\n",
    "\n",
    "  // Returns the inputs handle shapes and types, for the resource tensor output\n",
    "  // at index <idx>. Returns NULL if the shape and types were not available.\n",
    "  const std::vector<ShapeAndType>* input_handle_shapes_and_types(int idx) {\n",
    "    return input_handle_shapes_and_types_[idx].get();\n",
    "  }\n",
    "\n",
    "  void set_output_handle_shapes_and_types(\n",
    "      int idx, const std::vector<ShapeAndType>& shapes_and_types) {\n",
    "    output_handle_shapes_and_types_[idx].reset(\n",
    "        new std::vector<ShapeAndType>(shapes_and_types));\n",
    "  }\n",
    "\n",
    "  // Note that shape functions should usually call MakeShapeFromShapeTensor,\n",
    "  // as it does more analysis to provide partial shapes.\n",
    "  //\n",
    "  // Returns in <out> a new shape whose dimension sizes come from tensor <t>.\n",
    "  // The tensor must be a 1-dimensional int32 or int64 tensor.  If <t> is NULL,\n",
    "  // then an unknown shape is returned.\n",
    "  Status MakeShapeFromTensor(const Tensor* t, ShapeHandle tensor_shape,\n",
    "                             ShapeHandle* out);\n",
    "\n",
    "  int graph_def_version() const { return graph_def_version_; }\n",
    "\n",
    "  const std::vector<std::pair<ShapeHandle, ShapeHandle>>& MergedShapes() const {\n",
    "    return merged_shapes_;\n",
    "  }\n",
    "  const std::vector<std::pair<DimensionHandle, DimensionHandle>>& MergedDims()\n",
    "      const {\n",
    "    return merged_dims_;\n",
    "  }\n",
    "\n",
    "  // Adds new outputs; useful when mutating the graph.\n",
    "  Status ExpandOutputs(int new_output_size);\n",
    "\n",
    " private:\n",
    "  // Creates and stores shapes for use in InferenceContext.\n",
    "  class ShapeManager {\n",
    "   public:\n",
    "    ShapeManager();\n",
    "    ~ShapeManager();\n",
    "\n",
    "    // Returns a new shape with the given dims. The returned value is owned by\n",
    "    // this class.\n",
    "    ShapeHandle MakeShape(const std::vector<DimensionHandle>& dims);\n",
    "\n",
    "    // Returns a new unknown shape.\n",
    "    ShapeHandle UnknownShape();\n",
    "\n",
    "    // Returns a new dimension of the given size.  The returned value\n",
    "    // is owned by this class.\n",
    "    inline DimensionHandle MakeDim(DimensionOrConstant d) {\n",
    "      if (d.dim.IsSet()) {\n",
    "        return d.dim;\n",
    "      } else {\n",
    "        all_dims_.push_back(new Dimension(d.val));\n",
    "        return all_dims_.back();\n",
    "      }\n",
    "    }\n",
    "\n",
    "   private:\n",
    "    std::vector<Shape*> all_shapes_;    // values are owned.\n",
    "    std::vector<Dimension*> all_dims_;  // values are owned.\n",
    "  };\n",
    "\n",
    "  friend class ::tensorflow::grappler::GraphProperties;\n",
    "\n",
    "  // Friend for user-defined function shape inference purposes.\n",
    "  friend class ::tensorflow::ShapeRefiner;\n",
    "\n",
    "  friend class ShapeInferenceTest;      // For testing Relax functions.\n",
    "  friend class ShapeInferenceTestutil;  // For testing shapes.\n",
    "\n",
    "  // Shared initialization across the two constructors.  Remove\n",
    "  // once we get rid of one of them.\n",
    "  void PreInputInit(const OpDef& op_def,\n",
    "                    const std::vector<const Tensor*>& input_tensors,\n",
    "                    const std::vector<ShapeHandle>& input_tensors_as_shapes);\n",
    "  void PostInputInit(std::vector<std::unique_ptr<std::vector<ShapeAndType>>>\n",
    "                         input_handle_data);\n",
    "\n",
    "  DimensionHandle GetDimension(const DimensionOrConstant& d);\n",
    "\n",
    "  Status ReturnUnknownShape(ShapeHandle* out) {\n",
    "    *out = UnknownShape();\n",
    "    return Status::OK();\n",
    "  }\n",
    "  Status ReturnCreatedShape(const std::vector<DimensionHandle>& dims,\n",
    "                            ShapeHandle* out) {\n",
    "    *out = MakeShape(dims);\n",
    "    return Status::OK();\n",
    "  }\n",
    "\n",
    "  // Adds additional context to the given status.\n",
    "  Status AttachContext(const Status& status);\n",
    "\n",
    "  // Relaxes an existing value <d_old> with a new value <d_new> and returns the\n",
    "  // relaxed dimension in <*out>. If <d_old> and <d_new> have incompatible\n",
    "  // values, returns an error.\n",
    "  //\n",
    "  // Note that <*out> may be set to <d_old> or <d_new>.\n",
    "  void Relax(DimensionHandle d_old, DimensionHandle d_new,\n",
    "             DimensionHandle* out);\n",
    "  // Relaxes an existing shape <s_old> with a new shape <s_new> and returns the\n",
    "  // relaxed shape in <*out>. See 'RelaxInput' function for full details and\n",
    "  // examples.\n",
    "  void Relax(ShapeHandle s_old, ShapeHandle s_new, ShapeHandle* out);\n",
    "\n",
    "  // Used to implement MergeInputHandleShapesAndTypes and\n",
    "  // MergeOutputHandleShapesAndTypes.\n",
    "  bool MergeHandleShapesAndTypes(\n",
    "      const std::vector<ShapeAndType>& shapes_and_types,\n",
    "      std::vector<ShapeAndType>* to_update) TF_MUST_USE_RESULT;\n",
    "  // Used to implement RelaxInputHandleShapesAndMergeTypes and\n",
    "  // RelaxOutputHandleShapesAndMergeTypes.\n",
    "  bool RelaxHandleShapesAndMergeTypes(\n",
    "      const std::vector<ShapeAndType>& shapes_and_types,\n",
    "      std::vector<ShapeAndType>* to_update) TF_MUST_USE_RESULT;\n",
    "\n",
    "  // Forget all the previous merged shapes and dims.\n",
    "  void ForgetMerges() {\n",
    "    merged_shapes_.clear();\n",
    "    merged_dims_.clear();\n",
    "  }\n",
    "\n",
    "  // Helper method for MakeShapeFromTensor and MakeShapeFromShapeTensor.\n",
    "  Status InternalMakeShapeFromTensor(\n",
    "      bool treat_unknown_scalar_tensor_as_unknown_shape, const Tensor* t,\n",
    "      ShapeHandle tensor_shape, ShapeHandle* out);\n",
    "\n",
    "  ShapeManager shape_manager_;\n",
    "\n",
    "  // inputs_, outputs_, and input_tensors_as_shapes_ refer to values from\n",
    "  // `shape_manager_`.\n",
    "  std::vector<ShapeHandle> inputs_;\n",
    "  std::vector<const Tensor*> input_tensors_;\n",
    "  std::vector<bool> requested_input_tensor_;\n",
    "  std::vector<ShapeHandle> outputs_;\n",
    "  // Can have fewer elements than inputs_.\n",
    "  std::vector<ShapeHandle> input_tensors_as_shapes_;\n",
    "  std::vector<bool> requested_input_tensor_as_partial_shape_;\n",
    "\n",
    "  // input_handle_shapes_and_types_[i] is the list of shape/type pairs available\n",
    "  // through the resource handle passed along input i of the node.\n",
    "  //\n",
    "  // Values may be NULL.\n",
    "  std::vector<std::unique_ptr<std::vector<ShapeAndType>>>\n",
    "      input_handle_shapes_and_types_;\n",
    "\n",
    "  // output_handle_shapes_and_types_[i] is the list of shape/type pairs\n",
    "  // available through the resource handle passed along output i of the node.\n",
    "  //\n",
    "  // Values may be NULL.\n",
    "  std::vector<std::unique_ptr<std::vector<ShapeAndType>>>\n",
    "      output_handle_shapes_and_types_;\n",
    "\n",
    "  const int graph_def_version_;\n",
    "  const NodeDef* node_def_;\n",
    "  NameRangeMap input_name_map_;\n",
    "  NameRangeMap output_name_map_;\n",
    "\n",
    "  // An error set during construction. TODO(cwhipkey): remove when test\n",
    "  // constructor is removed.\n",
    "  Status construction_status_;\n",
    "\n",
    "  // Pair of shape or dim handles that are equivalent, ie that represent the\n",
    "  // same underlying shape of dimension. Note that for each pair at least one of\n",
    "  // the handles must contain an unknown shape, since we don't keep track of\n",
    "  // known shapes or dims here.\n",
    "  std::vector<std::pair<ShapeHandle, ShapeHandle>> merged_shapes_;\n",
    "  std::vector<std::pair<DimensionHandle, DimensionHandle>> merged_dims_;\n",
    "\n",
    "  TF_DISALLOW_COPY_AND_ASSIGN(InferenceContext);\n",
    "};\n",
    "```\n",
    "\n",
    "具体的 Rank ， Status 检查等操作直接看这个文件的 API 即可。如常用的：\n",
    "\n",
    "- `WithRank` , 检查 Rank 并且返回 shape.\n",
    "\n",
    "  ```c++\n",
    "    // If <shape> has rank <rank>, or its rank is unknown, return OK and return\n",
    "    // the shape with asserted rank in <*out>. Otherwise return an error.\n",
    "    //\n",
    "    // Note that <*out> may be set to <shape>.\n",
    "    Status WithRank(ShapeHandle shape, int64 rank,\n",
    "                    ShapeHandle* out) TF_MUST_USE_RESULT;\n",
    "  ```\n",
    "\n",
    "- `Dim`, 返回相应维度的  Dim\n",
    "\n",
    "  ```c++\n",
    "  // idx can be negative for an offset from end of dimensions.\n",
    "  // idx must be in the range [-1 * s.rank, s.rank).\n",
    "  DimensionHandle Dim(ShapeHandle s, int64 idx) {\n",
    "    if (s->rank_ == kUnknownRank) {\n",
    "      return UnknownDim();\n",
    "    }\n",
    "    return DimKnownRank(s, idx);\n",
    "  }\n",
    "  ```\n",
    "\n",
    "- `Merge`\n",
    "\n",
    "  ```c++\n",
    "    // Merges <s0> and <s1> and returns the merged shape in <*out>. See\n",
    "    // 'MergeInput' function for full details and examples.\n",
    "    Status Merge(ShapeHandle s0, ShapeHandle s1,\n",
    "                 ShapeHandle* out) TF_MUST_USE_RESULT;\n",
    "  ```\n",
    "\n",
    "- `Matrix`\n",
    "\n",
    "  ```c++\n",
    "  // Returns a new shape of two dimensions.\n",
    "  ShapeHandle Matrix(DimensionOrConstant dim1, DimensionOrConstant dim2);\n",
    "  ```\n",
    "\n",
    "到目前为止终于把注册这一步给完成了。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
