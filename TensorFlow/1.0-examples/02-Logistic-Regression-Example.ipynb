{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Example\n",
    "\n",
    "以 MNIST 为例，将 (28, 28) 转置成 (784, 1) 个 fetures 来处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = tf.Graph()\n",
    "with g1.as_default():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(train_data)\n",
    "    iterator = tf.data.make_one_shot_iterator(dataset)\n",
    "    next_element = iterator.get_next()\n",
    "    \n",
    "    W = tf.Variable(tf.random.normal([10, 784]), name=\"weights\")\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        sess.run(init_op)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如何使用一个 Initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.0230905   0.52107584  0.38565353]\n",
      " [ 0.11472052  1.0831474   1.5300333 ]]\n"
     ]
    }
   ],
   "source": [
    "# 实例化一个 initializer, 但是想成为计算图中的一个节点，还需要我们调用相应的 API 函数。\n",
    "# 如调用 __call__()\n",
    "\n",
    "g2 = tf.Graph()\n",
    "with g2.as_default():\n",
    "    weights = tf.random_normal_initializer()\n",
    "    init = weights((2, 3))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        print(sess.run(init))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如何将 Initializer 与 tf.Variable 相结合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其实查看文档可以知道每一个 `tf.Variable` 对象都且个 `initializer` OP 可以让我们进行初始化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.24014388 -0.0208146  -0.34707728]\n",
      " [-0.98216105  0.5356388  -0.15996137]\n",
      " [-0.736439   -0.19126625  0.0421228 ]]\n"
     ]
    }
   ],
   "source": [
    "g3 = tf.Graph()\n",
    "with g3.as_default():\n",
    "    w = tf.Variable(tf.random.normal((3,3), name=\"weights\"))\n",
    "    eye3 = tf.eye(3)\n",
    "    a = tf.matmul(w, eye3)\n",
    "    init_op = w.initializer\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)   # 一定要记得初始化\n",
    "        print(sess.run(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有时候，我不必为所有 Variables 都单独执行 op。 我可以使用一个全局的 op 来完成初始化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.4287577e+00 -6.6445392e-01 -9.6790987e-01]\n",
      " [-9.7193003e-01 -5.9794134e-01 -1.0857213e+00]\n",
      " [-1.7487629e-01  1.3640827e-03 -1.2540774e-02]]\n"
     ]
    }
   ],
   "source": [
    "g4 = tf.Graph()\n",
    "with g4.as_default():\n",
    "    w = tf.Variable(tf.random.normal((3,3), name=\"weights\"))\n",
    "    e = tf.Variable(tf.eye(3), name=\"indentity\")\n",
    "    a = tf.matmul(w, e)\n",
    "    \n",
    "    init_all_op = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_all_op)   # 一定要记得初始化\n",
    "        print(sess.run(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "epochs = 25\n",
    "batch_size = 100\n",
    "\n",
    "x = tf.placeholder(tf.float32, [784, 1])\n",
    "y = tf.placeholder(tf.float32, [10, 1])\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(tf.zeros([10, 784]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# Construct model\n",
    "pred = tf.nn.softmax(tf.matmul(W, x) + b)\n",
    "\n",
    "# Minimize error using cross entropy\n",
    "cost = tf.reduce_sum(-tf.reduce_sum(y * tf.log(pred)))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
