{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(batch_size=100):\n",
    "    \"\"\"\n",
    "    注意：关于 dataset 的操作都会返回一个新的 dataset, 另忘记用新的变量去接收。\n",
    "    \"\"\"\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "    train, test = mnist.load_data()\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(train)\n",
    "    train_dataset = train_dataset.map(lambda x,y: (tf.reshape(x, [784,]), tf.one_hot(y, 10)))\n",
    "    train_dataset = train_dataset.repeat(100).batch(batch_size)\n",
    "    \n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices(test)\n",
    "    test_dataset = test_dataset.map(lambda x,y: (tf.reshape(x, [784,]), tf.one_hot(y, 10)))\n",
    "    test_dataset = test_dataset.batch(100)\n",
    "\n",
    "    return train_dataset, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "batch_size = 100\n",
    "n_samples = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(graph):\n",
    "    with graph.as_default():\n",
    "        x = tf.placeholder(dtype=tf.float32,\n",
    "                          shape=(None, 784), name='x')\n",
    "        y = tf.placeholder(dtype=tf.float32,\n",
    "                          shape=(None, 10), name='y')\n",
    "        \n",
    "        with tf.variable_scope('LR'):\n",
    "            w = tf.Variable(tf.zeros([784, 10]))\n",
    "            b = tf.Variable(tf.zeros([10]))\n",
    "            \n",
    "            pred = tf.nn.softmax(tf.matmul(x, w) + b)\n",
    "            \n",
    "            # 用 tf.clip_by_value 防止计算时出现  inf \n",
    "            loss = tf.reduce_mean(\n",
    "                -tf.reduce_sum(y * tf.log(tf.clip_by_value(pred,1e-10,1.0)), reduction_indices=1)\n",
    "            )\n",
    "    return x, y, loss, pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    g1 = tf.Graph()\n",
    "    with g1.as_default():\n",
    "        train_dataset, test_dataset = get_dataset(batch_size)\n",
    "        train_iterator = tf.data.make_one_shot_iterator(train_dataset)\n",
    "        train_next_element = train_iterator.get_next()\n",
    "        \n",
    "        test_iterator = tf.data.make_one_shot_iterator(test_dataset)\n",
    "        test_next_element = test_iterator.get_next()\n",
    "        \n",
    "        x, y, loss, pred = model(g1)\n",
    "        \n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            tf.summary.FileWriter('./logs/logistic-reg-mnist', sess.graph)\n",
    "            \n",
    "            sess.run(init)\n",
    "            \n",
    "            n_batches = int(n_samples / batch_size)\n",
    "            print('Start:')\n",
    "            for epoch in range(epochs):\n",
    "                avg_loss = 0\n",
    "                for batch in range(n_batches):\n",
    "                    x_train, y_train = sess.run(train_next_element)\n",
    "                    feed_dict = {x: x_train, y: y_train}\n",
    "                    loss_val, _ = sess.run([loss, optimizer], feed_dict)\n",
    "                    avg_loss += loss_val / n_samples\n",
    "                print('Epoch ', epoch + 1, \" : loss = \", avg_loss)\n",
    "            \n",
    "            # 测试 accuracy\n",
    "            acc = 0\n",
    "            total_test = 0\n",
    "            try:\n",
    "#                 while True:\n",
    "                    x_test, y_test = sess.run(test_next_element)\n",
    "                    feed_dict = {x: x_test}\n",
    "                    total_test += x_test.shape[0]\n",
    "                    y_pred = sess.run(pred, feed_dict)\n",
    "                    p_idx = tf.argmax(y_pred, 1)\n",
    "                    t_idx = tf.argmax(y_test, 1)\n",
    "                    equal_idx = tf.equal(p_idx, t_idx)\n",
    "                    equals = tf.cast(equal_idx, dtype=tf.float32)\n",
    "                    acc += sess.run(tf.reduce_sum(equals))\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                print(\"Iterator Finished\")\n",
    "        print('Last loss:', avg_loss) \n",
    "        print('total_test:', total_test)\n",
    "        print('accuracy:', (acc / total_test) * 100, '%') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start:\n",
      "Epoch  1  : loss =  0.0892284685492515\n",
      "Epoch  2  : loss =  0.06995963064034778\n",
      "Epoch  3  : loss =  0.064606470644474\n",
      "Epoch  4  : loss =  0.06359267535209655\n",
      "Epoch  5  : loss =  0.061362683415412886\n",
      "Epoch  6  : loss =  0.06108994638522466\n",
      "Epoch  7  : loss =  0.059992963830630026\n",
      "Epoch  8  : loss =  0.059530436972777004\n",
      "Epoch  9  : loss =  0.0592103311181068\n",
      "Epoch  10  : loss =  0.05853665634393688\n",
      "Last loss: 0.05853665634393688\n",
      "total_test: 100\n",
      "accuracy: 83.0 %\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个例子，完整的说明了 tf 1.0 怎样去训练，测试。\n",
    "\n",
    "1. 定义模型\n",
    "2. 数据集处理\n",
    "\n",
    "<img src=\"Logistic-Regression-Mnist.png\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
