{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Hinge Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM 的优化函数也可以从 Hinge Loss （合页损失函数）来解释。 Hinge Loss 的公式是：\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{N}[1 - y_i(w^T x_i + b)]_{+} + \\lambda\\|w\\|^2 \\\\ \n",
    "[z]_{+} =\\begin{cases}\n",
    "               z, \\space z \\gt 0 \\\\\n",
    "               0, \\space z \\leqslant 0 \\\\\n",
    "            \\end{cases}\n",
    "            \\tag{1}\n",
    "$$\n",
    "\n",
    "SVM 中 $y \\in \\{+1, -1\\}$。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中，第一项是损失，第二项是正则化项。\n",
    "\n",
    "这个公式说明，当 $y_i(w^T x_i + b) > 1$ 时，loss 为 0。否则 Loss 为 $1- y_i(w^T x_i + b)$。\n",
    "\n",
    "对比下感知机损失函数 $[-y_i(w^T x_i + b)]_{+}$, Hinge Loss 不仅要分类正确，而且在置信度足够高的时候，损失才为 0, 因此对学习有更高的要求。\n",
    "\n",
    "<img src=\"https://pic4.zhimg.com/80/v2-0884e199d2198ec716f3b09536b10213_hd.jpg\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考\n",
    "\n",
    "1. [如何理解 SVM 中的 Hinge-Loss](https://www.zhihu.com/question/47746939)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
