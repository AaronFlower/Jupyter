{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost 算法实现\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataset():\n",
    "    X = np.array([\n",
    "        [1.0, 2.1],\n",
    "        [2.0, 1.1],\n",
    "        [1.3, 1.0],\n",
    "        [1.0, 1.0],\n",
    "        [2.0, 1.0]\n",
    "    ])\n",
    "    y = np.array([1.0, 1.0, -1.0, -1.0, 1.0]).reshape(5, 1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stumpClassify(X, dimen, threshVal, threshIneq):\n",
    "    '''\n",
    "    根据维度的阈值做一个简单的分类\n",
    "        - dataset: 样本集\n",
    "        - dimen : 数据维度\n",
    "        - threshVal: 阈值\n",
    "        - threshIneq: 比较操作符\n",
    "    '''\n",
    "    m, _ = X.shape\n",
    "    y_hat = np.ones((m, 1))\n",
    "    if threshIneq == 'lt':\n",
    "        y_hat[X[:, dimen] <= threshVal] = -1.0\n",
    "    else:\n",
    "        y_hat[X[:, dimen] > threshVal] = 1.0\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def exponentialLoss(y, y_hat):\n",
    "#     '''\n",
    "#     指数损失函数\n",
    "#     '''\n",
    "#     return sum(np.exp(-y * y_hat))\n",
    "\n",
    "def buildStump(X, y, D):\n",
    "    '''\n",
    "    在数据集 X 上根据权重 D 寻找最好的分类器。\n",
    "    - X 训练样本特征\n",
    "    - y 训练样本标签\n",
    "    - D 样本权重\n",
    "    对于每一维的特征，如何找到最佳的分隔点那？我们可以对特征的所有值\n",
    "    进行排序，然后依次对两个相邻的值除 2, 检测是否是最佳分隔点。\n",
    "    在这里我们用别一种方法，即寻找出最大和最小值，对其平均分隔 10 个\n",
    "    区间，看在区间的边界上是否是最佳分隔。\n",
    "    '''\n",
    "    m, n = X.shape\n",
    "    minErr = np.inf\n",
    "    bestStump = {}\n",
    "    bestY = np.zeros((m, 1))\n",
    "    intervals = 10\n",
    "    \n",
    "    for dim in range(n):\n",
    "        dmin = X[:,dim].min()\n",
    "        dmax = X[:,dim].max()\n",
    "        \n",
    "        span = (dmax - dmin) / intervals;\n",
    "        # 简单一点寻找 10 次划分即可.\n",
    "        for i in range(intervals):\n",
    "            threshVal = dmin + i * span\n",
    "            for op in ['lt', 'gt']:\n",
    "                y_hat = stumpClassify(X, dim, threshVal, op)\n",
    "                \n",
    "                errArr = np.ones((m, 1))\n",
    "                errArr[y_hat == y] = 0\n",
    "                # 注意 D 权重向量的用法。\n",
    "                err = np.dot(D.T, errArr).flatten()[0]\n",
    "                \n",
    "#                 print(\"split: dim {0}, thresh {1:0.2f}, op:{2}, err:{3:0.2f}%\".format(\n",
    "#                     dim, threshVal, op, err * 100\n",
    "#                 ))\n",
    "                if err < minErr:\n",
    "                    minErr = err\n",
    "                    bestY = y_hat.copy()\n",
    "                    bestStump['dim'] = dim\n",
    "                    bestStump['thresh'] = threshVal\n",
    "                    bestStump['op'] = op\n",
    "#     print(bestStump, minErr)\n",
    "    return bestStump, minErr, bestY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1) [[0.2 0.2 0.2 0.2 0.2]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'dim': 0, 'thresh': 1.3, 'op': 'lt'}, 0.2, array([[-1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [ 1.]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = loadDataset()\n",
    "m, n = X.shape\n",
    "\n",
    "# 测试\n",
    "\n",
    "D = np.ones((m, 1))/m\n",
    "print(D.shape, D.T)\n",
    "buildStump(X, y, D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoost():\n",
    "    def __init__(self, n_estimators = 10):\n",
    "        '''\n",
    "        初始化函数：\n",
    "            - n_estimators 需要多少个弱分类器\n",
    "        '''\n",
    "        assert n_estimators > 0\n",
    "        self.estimators = []\n",
    "        self.alphas = []\n",
    "        self.n_estimators = n_estimators\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        复用 AdaBoost 算法来生成分类器。\n",
    "        '''\n",
    "        m, n = X.shape\n",
    "        D = np.ones((m, 1)) / m\n",
    "        epsilon = 0.0001\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            stump, err, y_hat = buildStump(X, y, D)\n",
    "#             print(stump, err, y_hat)\n",
    "            # 防止 err 为 0 造成无法收敛。\n",
    "            err  += epsilon \n",
    "            alpha = 0.5 * np.log((1 - err) / err)\n",
    "            # new weights and renormalization\n",
    "            D = D * np.exp(-alpha * y * y_hat)\n",
    "#             print(alpha,D)\n",
    "            D = D / np.sum(D) # keep sum(D) = 1\n",
    "            \n",
    "            \n",
    "            self.alphas.append(alpha)\n",
    "            self.estimators.append(stump)\n",
    "        return\n",
    "    \n",
    "    def predict(self, X):\n",
    "        m, _ = X.shape\n",
    "        y_hat = np.zeros((m, 1))\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            stump = self.estimators[i]\n",
    "            y_hat += self.alphas[i] * stumpClassify(X, stump['dim'], stump['thresh'], stump['op'])\n",
    "        return np.sign(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoost(10)\n",
    "clf.fit(X, y)\n",
    "y_hat = clf.predict(X)\n",
    "m, n = X.shape\n",
    "accuracy = np.sum(y_hat == y) / m * 100.0\n",
    "print('accuracy: {0:0.2f}%'.format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 estimators, accuracy: 80.00%\n",
      "12 estimators, accuracy: 80.00%\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt('test-ada.txt')\n",
    "X = data[:,0:2]\n",
    "y = data[:,2].reshape(-1, 1)\n",
    "\n",
    "train_X, train_y = X[0:80], y[0:80]\n",
    "test_X, test_y = X[80:-1], y[80:-1]\n",
    "\n",
    "for i in range(8, 16, 4):\n",
    "    clf = AdaBoost(i)\n",
    "    clf.fit(train_X, train_y)\n",
    "    y_hat = clf.predict(test_X)\n",
    "\n",
    "    accuracy = np.sum(y_hat == test_y) / m * 100.0\n",
    "    print('{0} estimators, accuracy: {1:0.2f}%'.format(i, accuracy))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a12be33a0882>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 使用 scikit 来测试下, 那问题来了？如果特征均分刚好可以二分怎么办？ 其前面的误判为 0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_iris\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_iris\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# 使用 scikit 来测试下, 那问题来了？如果特征均分刚好可以二分怎么办？ 其前面的误判为 0.\n",
    "from sklearn.datasets import load_iris\n",
    "X, y = load_iris(True)\n",
    "\n",
    "X, y = X[0:100], y[0:100]\n",
    "y[0:50] = -1\n",
    "\n",
    "idx = np.random.permutation(100)\n",
    "X = X[idx]\n",
    "y = y[idx]\n",
    "\n",
    "train_X, train_y = X[0:80], y[0:80].reshape(-1, 1)\n",
    "test_X, test_y = X[80:-1], y[80:-1].reshape(-1, 1)\n",
    "\n",
    "clf = AdaBoost(2)\n",
    "clf.fit(train_X, train_y)\n",
    "y_hat = clf.predict(test_X)\n",
    "\n",
    "accuracy = np.sum(y_hat == test_y) / 20 * 100.0\n",
    "print('{0} estimators, accuracy: {1:0.2f}%'.format(i, accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
