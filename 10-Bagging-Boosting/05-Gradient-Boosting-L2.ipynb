{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM L2\n",
    "\n",
    "Gradient Boosting 的前奏。选用简单的 MSE 来寻找残差的最佳划分。\n",
    "\n",
    "这里有一个很好的解释，[GBM - MSE](http://explained.ai/gradient-boosting/L2-loss.html)\n",
    "\n",
    "实现一个最常用的 GBM。它是通过不断优化 MSE, 即称了 L2 cost 来完成建模。L2 的缺点是对 outlier 点敏感。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    return pd.read_csv('rent.txt', delimiter='\\t')\n",
    "\n",
    "class DecisionTree(object):\n",
    "    '''\n",
    "        构建用于回归的决策树桩\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        return \n",
    "    \n",
    "    def model(self, X, y):\n",
    "        m, n = X.shape\n",
    "        split_feature = 0\n",
    "        split_val = 0\n",
    "        lmean, rmean = 0, 0\n",
    "        min_mse = np.inf\n",
    "        for i in range(n):\n",
    "            vals = list(set(X[:, i]))\n",
    "            vals.sort()\n",
    "            candidates = [(vals[i] + vals[i + 1]) / 2 for i in range(len(vals) - 1)]\n",
    "            for c in candidates:\n",
    "                xVals = X[:, i]\n",
    "                mse = np.var(y[xVals <= c]) + np.var(y[xVals > c])\n",
    "                if mse <= min_mse:\n",
    "                    min_mse, split_feature, split_val = mse, i, c\n",
    "                    lmean, rmean = round(np.mean(y[xVals <= c]), 2), round(np.mean(y[xVals > c]), 2)\n",
    "                    \n",
    "        self.split_feature = split_feature\n",
    "        self.split_val = split_val\n",
    "        self.lmean, self.rmean = lmean, rmean\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        m = X.shape[0]\n",
    "        y = np.ones(m) * self.lmean\n",
    "        ridx = X[:, self.split_feature] > self.split_val\n",
    "        y[ridx] = self.rmean\n",
    "        return y      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoostMse(object):\n",
    "    def __init__(self):\n",
    "        self.trees = []\n",
    "        self.f0 = 0\n",
    "        return\n",
    "    \n",
    "    def model(self, X, y, alpha = 1, iters = 10):\n",
    "        self.alpha, self.iters = alpha, iters\n",
    "        self.f0 = np.mean(y)\n",
    "        m = X.shape[0]\n",
    "        yHat = np.ones(m) * self.f0\n",
    "        for t in range(iters):\n",
    "            residuals = y - yHat\n",
    "            print(t, y, yHat, residuals)\n",
    "            tree = DecisionTree().model(X, residuals)\n",
    "            yHat = yHat + alpha * tree.predict(X)\n",
    "            self.trees.append(tree)\n",
    "            \n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        m = X.shape[0]\n",
    "        yHat = np.ones(m) * self.f0\n",
    "        for i in range(self.iters):\n",
    "            yHat = yHat + self.alpha * self.trees[i].predict(X)\n",
    "            \n",
    "        return yHat\n",
    "    \n",
    "    def printTrees(self):\n",
    "        print('F0:', self.f0)\n",
    "        for i in range(self.iters):\n",
    "            tree = self.trees[i]\n",
    "            print('Tree ', i)\n",
    "            print('\\t split feature:', tree.split_feature)\n",
    "            print('\\t split feature:', tree.split_val)\n",
    "            print('\\t left mean', tree.lmean)\n",
    "            print('\\t right mean', tree.rmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [1200 1280 2000 1450 1160] [1418. 1418. 1418. 1418. 1418.] [-218. -138.  582.   32. -258.]\n",
      "1 [1200 1280 2000 1450 1160] [1272.5 1272.5 2000.  1272.5 1272.5] [ -72.5    7.5    0.   177.5 -112.5]\n",
      "2 [1200 1280 2000 1450 1160] [1180.   1334.17 2061.67 1334.17 1180.  ] [ 20.   -54.17 -61.67 115.83 -20.  ]\n",
      "F0: 1418.0\n",
      "Tree  0\n",
      "\t split feature: 0\n",
      "\t split feature: 925.0\n",
      "\t left mean -145.5\n",
      "\t right mean 582.0\n",
      "Tree  1\n",
      "\t split feature: 0\n",
      "\t split feature: 825.0\n",
      "\t left mean -92.5\n",
      "\t right mean 61.67\n",
      "Tree  2\n",
      "\t split feature: 0\n",
      "\t split feature: 925.0\n",
      "\t left mean 15.41\n",
      "\t right mean -61.67\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1195.41, 1349.58, 2000.  , 1349.58, 1195.41])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data()\n",
    "X,y = df.values[:, :-1], df.values[:,-1]\n",
    "bmse = BoostMse().model(X, y, 1, 3)\n",
    "bmse.printTrees()\n",
    "bmse.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
