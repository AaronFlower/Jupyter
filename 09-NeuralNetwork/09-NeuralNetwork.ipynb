{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "\n",
    "æ„å»ºä¸€ä¸ªç¥ç»ç½‘ç»œæ¥è®¤è¯†æ•°å­— MNISTã€‚ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### åˆå§‹åŒ–åŠ è½½åº“\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. åŠ è½½æ•°æ® \n",
    "é¦–å…ˆçœ‹ä¸€ä¸‹æ•°æ®é•¿ä»€ä¹ˆæ ·å­ã€‚è¿™æ ·æœ€ç›´è§‚ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "\n",
    "def load_data ():\n",
    "    \"\"\"\n",
    "        è¿”å›: (train_data, val_date, test_data)\n",
    "    \"\"\"\n",
    "    f = gzip.open('./mnist.pkl.gz', 'rb')\n",
    "    train_data, val_data, test_data = pickle.load(f, encoding='bytes')\n",
    "    f.close()\n",
    "    return (train_data, val_data, test_data)\n",
    "\n",
    "def load_data_wrapper ():\n",
    "    \"\"\"\n",
    "        ç”±äºè¿›è¡Œæ•°å­—è®¤è¯†æ˜¯ä¸€ä¸ªå¤šåˆ†ç±»(multi-classifier)é—®é¢˜ï¼Œ\n",
    "        æ‰€ä»¥å¯ä»¥å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œä¸‹é¢„å¤„ç†:\n",
    "             1. ä½¿æ ·æœ¬çš„ç‰¹å¾çš„ shape ä» (784,) å˜æˆ (784, 1)\n",
    "             2. ä½¿åˆ†ç±»æ ‡ç­¾å˜é‡å˜æˆ (10, 1) , ä»…é’ˆå¯¹è®­ç»ƒæ•°æ®ã€‚\n",
    "    \"\"\"\n",
    "    train_data, val_data, test_data = load_data()\n",
    "    train_X = [x.reshape(784, 1) for x in train_data[0]]\n",
    "    train_y = [vectorize(y) for y in train_data[1]]\n",
    "    \n",
    "    val_X = [x.reshape(784, 1) for x in val_data[0]]\n",
    "    test_X = [x.reshape(784, 1) for x in test_data[0]]\n",
    "    \n",
    "    return (\n",
    "        zip(train_X, train_y), \n",
    "        zip(val_X, val_data[1]),\n",
    "        zip(test_X, test_data[1])\n",
    "    )\n",
    "\n",
    "def vectorize(y):\n",
    "    '''\n",
    "        è¿”å›ä¸€ä¸ª shape ä¸º (10, 1) çš„ column vector.\n",
    "    '''\n",
    "    e = np.zeros((10, 1))\n",
    "    e[y] = 1.0\n",
    "    return e\n",
    "    \n",
    "def get_images (data):\n",
    "    images, _ = data\n",
    "    return [img.reshape(28, -1) for img in images]\n",
    "\n",
    "def plot_images6 (images):\n",
    "    \"Random plot six MNIST images separately\"\n",
    "    ilist = np.random.permutation(range(len(images)))\n",
    "    fig = plt.figure()\n",
    "    for j in range(1, 7):\n",
    "        ax = fig.add_subplot(1, 6, j)\n",
    "        ax.matshow(images[ilist[j]], cmap = matplotlib.cm.binary)\n",
    "        plt.xticks(np.array([]))\n",
    "        plt.yticks(np.array([]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " train_data <class 'tuple'> 2\n",
      "X: <class 'numpy.ndarray'> (50000, 784) (784,)\n",
      "y: <class 'numpy.ndarray'> (50000,)\n",
      "\n",
      " val_data <class 'tuple'> 2\n",
      "X: <class 'numpy.ndarray'> (10000, 784) (784,)\n",
      "y: <class 'numpy.ndarray'> (10000,)\n",
      "\n",
      " test_data <class 'tuple'> 2\n",
      "X: <class 'numpy.ndarray'> (10000, 784) (784,)\n",
      "y: <class 'numpy.ndarray'> (10000,)\n"
     ]
    }
   ],
   "source": [
    "def printDataInfo(data, name):\n",
    "    print(\"\\n\", name, type(data), len(data))\n",
    "    X, y = data\n",
    "    print('X:', type(X), X.shape, X[0].shape)\n",
    "    print('y:', type(y), y.shape)\n",
    "    \n",
    "printDataInfo(train_data, 'train_data')\n",
    "printDataInfo(val_data, 'val_data')\n",
    "printDataInfo(test_data, 'test_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä»ä¸Šé¢å¯ä»¥çœ‹å‡ºï¼Œæˆ‘ä»¬çš„æ•°æ®é›†å…±æœ‰ `70,000` ä¸ªæ ·æœ¬ï¼Œæ¯ä¸€ä¸ªæ ·æœ¬æ˜¯ `28 * 28 = 784` ä¸ªåƒç´ æ‰€ç»„æˆçš„å›¾ç‰‡ã€‚\n",
    "\n",
    "æˆ‘ä»¬å°† `70,000` ä¸ªæ ·æœ¬åˆ†æˆï¼š\n",
    "\n",
    "    - è®­ç»ƒæ•°æ®, training data: 50,000\n",
    "    - éªŒè¯æ•°æ®, validation data: 10,000\n",
    "    - æµ‹è¯•æ•°æ®, test data: 10,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = get_images(train_data)\n",
    "plot_images6(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### éªŒè¯ä¸‹å‡†å¤‡æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printData(data, name):\n",
    "    print(\"\\n\", name, type(data))\n",
    "    X, y = data\n",
    "    print('X:', type(X), X.shape)\n",
    "    print('y:', type(y), y.shape)\n",
    "    \n",
    "train_data, val_data, test_data = load_data_wrapper()  \n",
    "# print(type(train_data), train_data[0])\n",
    "# print(list(train_data))\n",
    "# printData(train_data, 'train_data')\n",
    "# printData(val_data, 'val_data')\n",
    "# printData(test_data, 'test_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ¨¡å‹æ„å»º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "å®ç°éšæœºæ¢¯åº¦ä¸‹é™ç‰ˆçš„ NN\n",
    "\"\"\"\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class Network(object):\n",
    "    \n",
    "    def __init__(self, sizes):\n",
    "        '''\n",
    "            sizes æ˜¯ NN æ¯å±‚çš„å•å…ƒæ•°ã€‚\n",
    "            Ex: sizes = [2, 3, 1]\n",
    "            åˆ™è¯´æ˜ï¼ŒNN å…±æœ‰ 3 å±‚ï¼Œå³ä¸€ä¸ªè¾“å…¥å±‚ï¼Œä¸€ä¸ªéšè—å±‚å’Œä¸€ä¸ªè¾“å‡ºå±‚ï¼Œ\n",
    "            æ¯å±‚çš„å•å…ƒä¸ªæ•°ï¼Œåˆ†åˆ«æ˜¯ 2, 3, 1.\n",
    "            æˆ‘ä»¬ä¸ºæ¯å±‚çš„å‚æ•°è¿›è¡Œåˆå§‹åŒ–ã€‚\n",
    "            æ³¨æ„ï¼šè¾“å…¥å±‚æ˜¯æ²¡æœ‰åç½® bias å‚æ•°çš„ã€‚\n",
    "        '''\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(nLayer, 1) for nLayer in sizes[1:]]\n",
    "        self.weights = [np.random.randn(nLayer, nPreLayer)\n",
    "                        for nLayer, nPreLayer in zip(sizes[1:], sizes[:-1])]\n",
    "        \n",
    "    def FP(self, a):\n",
    "        '''\n",
    "            ä½¿ç”¨ Feed Forward å°† a ä½œä¸ºè¾“å…¥å‚æ•°ï¼Œè¿”å›è¾“å‡ºå±‚ã€‚\n",
    "        '''\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigmoid(np.dot(w, a) + b)\n",
    "        return a\n",
    "    \n",
    "    def StochasticGD(self, train_data, epochs, mini_batch_size, alpha\n",
    "                    test_data = None):\n",
    "       '''\n",
    "           ä½¿ç”¨ mini-batch stochastic gradient descent æ¥è®­ç»ƒæ¨¡å‹ã€‚\n",
    "       '''\n",
    "        if test_data: n_test = len(test_data)\n",
    "        n = len(train_data)\n",
    "        for i in range(epochs):\n",
    "            random.shuffle(train_data)\n",
    "            mini_batches = [train_data[k: k + mini_batch_size] \n",
    "                            for k range(0, n, mini_batch_size)]\n",
    "            \n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, alpha)\n",
    "            if test_data:\n",
    "                print(\"Epoch {0}: {1} / {2}\".format(\n",
    "                    i, self.evaluate(test_data), n_test\n",
    "                ))\n",
    "            else:\n",
    "                print(\"Epock {0} complete\".format(i))\n",
    "    \n",
    "    def update_mini_batch(self, mini_batch, alpha):\n",
    "        '''\n",
    "            ä½¿ç”¨ BP æ¥æ›´æ–°å‚æ•°ã€‚\n",
    "        '''\n",
    "    def BP(self, x, y):\n",
    "        '''\n",
    "            å®ç° BPã€‚è¿”å›ä¸€ä¸ªå…ƒç»„ `(Nabla_b, Nabla_w)`\n",
    "        '''\n",
    "        \n",
    "                                        \n",
    "    \n",
    "\n",
    "### Miscellaneous functions\n",
    "def sigmoid(z):\n",
    "    ''' The sigmoid function '''\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    ''' Derivative of the sigmoid function '''\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta ä¸ Nabla\n",
    "Delta ğš« å’Œ Nabla ğ› ä¸€èˆ¬éƒ½å¯è¡¨ç¤ºå¾®åˆ†ç¬¦å·ï¼Œä¸€èˆ¬éƒ½ç§°ä¸º Laplace operatorã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n",
      "(3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.37811898],\n",
       "       [0.65908777]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes = [3, 4, 4, 2]\n",
    "nn = Network(sizes)\n",
    "X = np.random.randn(3, 1)\n",
    "print(X[0].shape)\n",
    "\n",
    "print(X.shape)\n",
    "nn.FP(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
