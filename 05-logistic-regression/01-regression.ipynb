{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression, 回归\n",
    "\n",
    "## 1. 概念\n",
    "\n",
    "什么是回归 (Regression) ? 当我们尝试预测的目标变量是连续的 (continuous) 值时，我们称这个学习问题是一个回归问题 (Regression Problem)。另外，当目标变量是一些离散值时，我们称这个学习问题是分类问题 (Classification Problem) 。\n",
    "\n",
    "## 2. 线性回归 ( Linear Regression)\n",
    "\n",
    "### 2.1 假设 (Hypothesis)\n",
    "为了在训练数据上执行监督学习，我们首先需要假设一个 **hypothesis** 目标函数， $h_{\\theta}(x)$, 假设有 k 个特征，则假设目标函数可以表示为一个线性函数：$h_{\\theta}(x) =  \\theta_0 + \\theta_1x_1 +  \\theta_2x_2 + ... +  \\theta_kx_k$,  $h_{\\theta}(x)$ 可以简写成  $h(x)$， 并且设 $x_0 = 1$ , 则有： \n",
    "\n",
    "\\begin{equation*}\n",
    "h(x) =  \\theta_0x_0 + \\theta_1x_1 +  \\theta_2x_2 + ... +  \\theta_kx_k = \\sum_{0}^{k}\\theta_i x_i = \\vec{\\theta}^\\top \\vec{x}\n",
    "\\end{equation*}\n",
    "\n",
    "那么对于给定的训练集，我们怎样学习取得到参数 $\\theta$ 那？ 一个合理的方法是让我们的目标函数 $h(x)$ 的输出结果最接近 $y$ , 至少在训练样本上保持最接近。 我们可以在训练集上定义一个代价函数(cost function) 来学习  $\\theta$。\n",
    "\n",
    "### 2.2 代价函数 (Cost Function)\n",
    "\n",
    "形式化来表示代价函数 $J(\\theta)$, 假设有 m 个训练样本:\n",
    "\n",
    "\\begin{equation*}\n",
    "J(\\theta) = \\frac{1}{2m} \\sum_{i}^{m}(h_{\\theta}(x^{(i)}) - y^{(i)}))^{2} \n",
    "\\end{equation*}\n",
    "\n",
    "我们的期望是目标函数至少在训练集上输出结果最接近，所以要使得 $J({\\theta})$ 最小化。我们需要求出使  $J({\\theta})$ 最小参数 $\\theta$。这个模型称之为最小二乘模型 (Least Mean Squares).\n",
    "\n",
    "求解函数最小值点的最常用方法当然就是梯度下降方法了。\n",
    "\n",
    "#### a. 梯度下降方法 (Gradient Descent)\n",
    "\n",
    "目标：求出  $J({\\theta})$ 的最小值点  $\\theta$。\n",
    "\n",
    "为了达到这个目标，让我们首个给  $\\theta$ 初始化一个值，然后用梯度下降的方法不断的变化  $\\theta$ ，使得  $J({\\theta})$ 变小，直到  $J({\\theta})$ 收敛。 则根据梯度下降法  $\\theta$ 的**更新公式**如下：\n",
    "\n",
    "\\begin{equation*}\n",
    "\\theta_j := \\theta_j - \\alpha \\frac{\\partial}{\\partial{\\theta_j}}J({\\theta})\n",
    "\\end{equation*}\n",
    "\n",
    "其中 $\\alpha$ 被称为学习因子。\n",
    "\n",
    "为了实现算法，我们需要求出偏导 $\\frac{\\partial}{\\partial{\\theta_j}}J({\\theta})$, 让我们首先假设只有一个训练样本的例子，忽略  $J({\\theta})$ 的求和公式。\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial}{\\partial{\\theta_j}}J({\\theta}) &= \\frac{\\partial}{\\partial{\\theta_j}} \\frac{1}{2}(h_{\\theta}(x) - y) ^ 2\n",
    "\\\\ &= (h_{\\theta}(x) - y) \\frac{\\partial}{\\partial{\\theta_j}} (h_{\\theta}(x) - y)\n",
    "\\\\ &= (h_{\\theta}(x) - y) \\frac{\\partial}{\\partial{\\theta_j}} (\\sum_{0}^{k}\\theta_i x_i -y)\n",
    "\\\\ &= (h_{\\theta}(x) - y)x_j\n",
    "\\end{align}\n",
    "\n",
    "对于仅有一个训练样本， $\\theta$ 的更新公式为：\n",
    "\n",
    "\\begin{equation*}\n",
    "\\theta_j :=  \\theta_j - \\alpha \\frac{\\partial}{\\partial{\\theta_j}}J({\\theta}) := \\theta_j - \\alpha (h_{\\theta}(x) - y)x_j\n",
    "\\end{equation*}\n",
    "\n",
    "可以证明当有 m 个训练样本是，$\\frac{\\partial}{\\partial{\\theta_j}} J({\\theta}) = \\sum_{i=1}^{m} (h_{\\theta}(x^{(i)}) - y^{(i)})x_j^{(i)}$, 则 $\\theta$ 的**更新公式**为：\n",
    "\n",
    "\\begin{equation*}\n",
    "\\theta_j := \\theta_j - \\frac{\\alpha}{m} \\sum_{i=1}^{m} (h_{\\theta}(x^{(i)}) - y^{(i)})x_j^{(i)}\n",
    "\\end{equation*}\n",
    "\n",
    "这个更新规则称为 LMS, 也称为 Widrow-Hoff 学习规则。这个规则看起来非常自然（natural and intuitive）, 因为每次更新的度是与公式中的误差项 $(h_{\\theta}(x^{(i)}) - y^{(i)})$ 成比例的。如果误差项很小时，我们只需要对参数进行很小的更新；反之，当误差项很大时，我们需要对参数进行很大的变更。\n",
    "\n",
    "使用梯度更新方法有两种方法： 批量梯度下降(Batch Gradient Descent) 与 随机梯度下降 (Stochastic Gradient Descent）.\n",
    "1. 批量梯度下降算法\n",
    "\n",
    "    Repeat Until Convergency {\n",
    "    \\begin{equation*}\n",
    "    \\theta_j := \\theta_j - \\frac{\\alpha}{m} \\sum_{i=1}^{m} (h_{\\theta}(x^{(i)}) - y^{(i)})x_j^{(i)}\n",
    "    \\end{equation*}\n",
    "    }\n",
    "    \n",
    "    需要注意，梯度下降方法很可能求得到一个局部的最优解，而不是一个全局的最优解。但是，我们线性回归用的梯度下降方法可以收敛到全局最优解，因为 $J({\\theta})$ 是一个凸二次函数(convex quadratic function).\n",
    "\n",
    "2. 随机梯度下降\n",
    "\n",
    "    随机梯度下降也称为增量梯度下降。算法如下：\n",
    "\n",
    "    Loop {\n",
    "        for i = 1 to m, {\n",
    "    \\begin{equation*}\n",
    "    \\theta_j := \\theta_j - \\alpha (h_{\\theta}(x^{(i)}) - y^{(i)})x_j^{(i)}\n",
    "    \\end{equation*}    \n",
    "        }\n",
    "    }\n",
    "    \n",
    "    在这个算法中，对训练集中的训练样本进行循环，每当遇到一个训练样本时，我们按照只有一个训练样本的更新规则来更新参数。\n",
    " \n",
    "Batch Gradient Descent 每一步更新参数，都需要扫描所有的训练样本，当 m 很大时会是一个非常耗时的操作。 而 Stochastic Gradient Descent 仅需要一个样本就可向前走一步，通常第二种方法收敛的更快。所以当 m 很大时，第二种方法是一个不错的选择。\n",
    "\n",
    "#### b. 矩阵求解 (Normal Equations)\n",
    "\n",
    "除了用梯度方法来求解，我们还可以使用矩阵来直接求解。平方误差可以写成 $\\frac{1}{2} \\sum_{i}^{m}(h_{\\theta}(x^{(i)}) - y^{(i)}))^{2}  = \\frac{1}{2} \\sum_{i}^{m}({x^{(i)}}^T \\theta - y^{(i)})^{2} $。用矩阵还可以写成 $ \\frac{1}{2} (X\\mathbf{\\theta} - Y)^T(X\\mathbf{\\theta} -Y) = J({\\theta})$。\n",
    "\n",
    "最小化 $J({\\theta})$ ，让其导数为 $ \\frac{\\partial}{\\partial{\\theta}}J({\\theta}) = 0 $, 我们可以得到正则方程 (Normal Equations) , $X^TX\\theta = X^TY$, 可以解出：\n",
    "\\begin{equation*}\n",
    "\\hat{\\theta} = (X^TX)^{-1}X^TY\n",
    "\\end{equation*}\n",
    "\n",
    "$\\theta$ 上的 ^ 表示，这是当前根据训练集估计出的最优 $\\theta$ 解，但可能并不是现有数据中真实的解，所以加上一个 ^ 表示是一个最佳估计。需要注意，正则方程需要保证 $X^TX$ 可逆，即 $(X^TX)^{-1}$ 存在。\n",
    "\n",
    "矩阵方法十分简单，在实现进也只需要几行代码即可完成。\n",
    "\n",
    "从线性代数的角度来看就很简单了，参数子空间投影矩阵篇。\n",
    "\n",
    "#### c. 牛顿法 (Newtown Method)\n",
    "\n",
    "求极值的方法还有一种是利用牛顿老爵爷的切线 (tangent) 法来实现，即要计算 Hessian 矩阵。具体计算方法有时间研究。\n",
    "\n",
    "### 2.3 代价函数的概率解释\n",
    "\n",
    "用上面方法求  $J({\\theta})$ 最小值。 那么为什么我们要把代价函数  $J({\\theta})$ 写成 $J(\\theta) = \\frac{1}{2} \\sum_{i}^{m}(h_{\\theta}(x^{(i)}) - y^{(i)}))^{2} $ 的形式那？我们可以尝试用概率的知识来解释这个问题。\n",
    "\n",
    "假设 $ y^{(i)} = \\theta^T x^{(i)} + \\varepsilon^{(i)} $, $ \\varepsilon^{(i)} $ 是误差项，用来捕获没有考虑到的其它特征的影响，或者是随机噪声 (random noise)。假设 $ \\varepsilon^{(i)}$ 是相互独立且同分布(IID, Independently and Identically Distributed) 并且属于高斯分布 (Gaussian Distribution) ，即正态分布 (Normal Distribution)，均值为 0 , 方差为 $ \\sigma^2 $：$ \\varepsilon^{(i)} \\sim  \\mathcal{N}(0, \\sigma^2)$ , 则有概率密度函数：\n",
    "\\begin{equation*}\n",
    "f(\\varepsilon^{(i)}) = \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{(\\varepsilon^{(i)})^2}{2\\sigma^2}}\n",
    "\\end{equation*}\n",
    "\n",
    "这也就意味着，固定 $\\theta$ , 给出 $ x^{(i)}$ 时，$ y^{(i)}$ 的概率密度为：\n",
    "\n",
    "\\begin{equation*}\n",
    "f(y^{(i)} \\mid x^{(i)}; \\space \\theta) = \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{(y^{(i)} - \\theta^T x^{(i)})^2}{2\\sigma^2}}\n",
    "\\end{equation*}\n",
    "\n",
    "则训练集的所有样本的联合概率密度函数为：\n",
    "\n",
    "\\begin{equation*}\n",
    "L(\\theta) = L(Y\\mid X; \\theta) = \\prod_{i=1}^{m}\\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{(y^{(i)} - \\theta^T x^{(i)})^2}{2\\sigma^2}}\n",
    "\\end{equation*}\n",
    "\n",
    "需要预估出 $\\theta$, 即最大化依然函数 $L$， 则有：\n",
    "\n",
    "\\begin{align*}\n",
    "\\ell(\\theta) &= \\ln{L(\\theta)} \n",
    "\\\\ &= \\ln \\prod_{i=1}^{m}\\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{(y^{(i)} - \\theta^T x^{(i)})^2}{2\\sigma^2}}\n",
    "\\\\ &= \\sum_{i=1}^{m}ln\\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{(y^{(i)} - \\theta^T x^{(i)})^2}{2\\sigma^2}}\n",
    "\\\\ &= m\\ln \\frac{1}{\\sqrt{2\\pi}\\sigma} - \\frac{1}{\\sigma^2} \\cdot \\frac{1}{2} \\sum_{i=1}^{m} (y^{(i)} - \\theta^T x^{(i)})^2\n",
    "\\end{align*}\n",
    "\n",
    "则可以看出最大化 $ \\ell(\\theta) $， 最终变成了最小化 $\\frac{1}{2} \\sum_{i=1}^{m} (y^{(i)} - \\theta^T x^{(i)})^2$ 。 这与我们的代价函数  $J({\\theta})$ 是一致的。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
