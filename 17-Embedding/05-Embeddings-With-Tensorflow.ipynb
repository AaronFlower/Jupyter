{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings in TensorFlow\n",
    "\n",
    "在表示离散数值时如果用 one-hot 会很稀疏，效率不高。Embeddings 可通过训练来寻找单词之间的相似性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'cat', 'is', 'a', 'great', 'cat']\n"
     ]
    }
   ],
   "source": [
    "text = 'My cat is a great cat'\n",
    "tokens = text.lower().split()\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a        0\n",
       "my       1\n",
       "cat      2\n",
       "is       3\n",
       "great    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = set(tokens)\n",
    "vocab = pd.Series(range(len(vocab)), index=vocab)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>cat</th>\n",
       "      <th>great</th>\n",
       "      <th>is</th>\n",
       "      <th>my</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  cat  great  is  my\n",
       "0  0    0      0   0   1\n",
       "1  0    1      0   0   0\n",
       "2  0    0      0   1   0\n",
       "3  1    0      0   0   0\n",
       "4  0    0      1   0   0\n",
       "5  0    1      0   0   0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 0, 4, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_ids = vocab.loc[tokens].values\n",
    "word_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "# TensorFlow has an operation for one-hot encoding\n",
    "one_hot_inputs = tf.one_hot(inputs, len(vocab))\n",
    "\n",
    "transformed = tf.Session().run(one_hot_inputs, {inputs: word_ids})\n",
    "transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings with TensorFlow\n",
    "\n",
    "通过 Embeddings representation (Embeddings 表示），每一个单词都可以被表示为一个向量，这个向量的长度就是 Embedding_size.\n",
    "\n",
    "在这个例子中，我们将 embedding_size 的长度设置为 3, 即每个单词通过三个实数组成的向量来表示。\n",
    "\n",
    "另外，在这个例子中 `embeddings` 是随机生成的，所以并不能表示单词之间的任何关系，只是借鉴 word2vec 的思想，如果在 NN 的训练过程中，embeddings 是会被更新的。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.13878635  0.86863303 -1.6017141 ]\n",
      " [-0.21395133 -1.1467001   0.24122861]\n",
      " [ 1.9225732  -1.6799307   0.5026513 ]\n",
      " [-0.10037646  0.54069585  1.7154973 ]\n",
      " [-1.526876   -1.6427577  -0.0230563 ]\n",
      " [-0.21395133 -1.1467001   0.24122861]]\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 3\n",
    "\n",
    "inputs = tf.placeholder(tf.int32, [None], name='word_ids')\n",
    "\n",
    "# This is where the embedding vecots live \n",
    "# This will be modified by the optimiztion unless trainable=False\n",
    "# I choose random normal distribution but you can try other distribution\n",
    "embeddings = tf.random_normal(shape=(len(vocab), embedding_size))\n",
    "\n",
    "embedded = tf.nn.embedding_lookup(embeddings, inputs)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "transformed = sess.run(embedded, {inputs: word_ids})\n",
    "print(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.5956285 ,  1.3354356 , -0.23255636],\n",
       "       [ 0.859987  , -0.64641064, -0.65326685],\n",
       "       [ 1.0356464 ,  1.4639943 , -0.17944591],\n",
       "       [-0.86762327, -0.05347135, -0.8178174 ],\n",
       "       [-0.7942827 ,  0.3838643 ,  0.88105506]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.42670134, -0.26926398,  0.26791432],\n",
       "       [ 0.05090201, -1.3788782 ,  0.18103495]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(embedded, {inputs: [0, 2]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained embeddings\n",
    "\n",
    "像上面我们随机初始化的 embeddings，向量之间是没有任何关系的。为了寻找向量之间的相似性，我们可可以使用 word2vec 训练它们，或者使用已经训练好的向量。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "1. [Embeddings with TensorFlow](https://post2web.github.io/posts/embeddings-with-tensorflow/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
