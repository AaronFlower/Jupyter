{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CART\n",
    "\n",
    "CART, Classification And Regression Tree，是一个经典的机器学习算法。有一些知识点需要注意。\n",
    "\n",
    "\n",
    "CART 即可以用于分类，也可用于回归，但在处理这两类问题时，相应的划分准则和叶子结点值的生成方法是不同的。\n",
    "\n",
    "### 1. 划分准则\n",
    "\n",
    "#### 1.1 回归划分准则 \n",
    "\n",
    "1. LSD (Least Squared Deviation), 最小二乘偏差。（和 wiki 上的 Varaince Reduction 一样吧）\n",
    "2. LAD (Least Absolute Deivation), 最小绝对偏差。（对 Outlier) 不敏感。\n",
    "\n",
    "#### 1.2 分类划分准则 \n",
    "\n",
    "假设当前为 m 的节点上有 k 个类别，其在节点上所占的比率为 $p_{mk}$。\n",
    "\n",
    "1. MisClassification Error, 误分率\n",
    "2. Gini Index\n",
    "\n",
    "$$\n",
    "Gini\\_index = \\sum_{k}p_{mk}(1 - p_{mk})\n",
    "$$\n",
    "\n",
    "3. Entropy Index\n",
    "\n",
    "$$\n",
    "Ent = -\\sum_{k}p_{mk}\\log {p_{mk}}\n",
    "$$\n",
    "\n",
    "4. twoing (二分准则）\n",
    "\n",
    "    这上准则需要查资料参考下。\n",
    "    \n",
    "    \n",
    "### 2. 叶子生成准则\n",
    "\n",
    "#### 2.1 分类问题\n",
    "\n",
    "对于分类问题，叶子节点是标签类值，可以通过投票统计获得。\n",
    "\n",
    "#### 2.2 回归问题\n",
    "\n",
    "对于回归问题，叶子节点是具体的值，需要计算所有节点的平均值。\n",
    "\n",
    "\n",
    "\n",
    "### References\n",
    "\n",
    "1. [CART分类与回归树与GBDT(Gradient Boost Decision Tree)](https://www.cnblogs.com/peizhe123/p/6105696.html)\n",
    "2. [算法实现参考，ML-From-Scratch](https://github.com/eriklindernoren/ML-From-Scratch)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
